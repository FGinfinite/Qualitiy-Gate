#!/usr/bin/env python3
# Copyright 2024 Quality-Gate Project. All rights reserved.
# Licensed under the Apache License, Version 2.0

"""
éªŒè¯ Qwen3 â†’ Quality-Gate æ¨¡å‹è½¬æ¢çš„æ­£ç¡®æ€§

åŠŸèƒ½ï¼š
1. æ¯”è¾ƒåŸå§‹ Qwen3 æ¨¡å‹å’Œè½¬æ¢åçš„ Quality-Gate æ¨¡å‹æƒé‡
2. éªŒè¯åŸºç¡€æƒé‡å®Œå…¨åŒ¹é…
3. æ£€æŸ¥è´¨é‡é—¨æ§å±‚æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
4. æµ‹è¯•å‰å‘ä¼ æ’­å’Œ router_logits è¾“å‡º
5. ç”Ÿæˆè¯¦ç»†çš„æ¯”è¾ƒæŠ¥å‘Š
"""

import argparse
import os
import sys

import torch
from transformers import AutoModelForCausalLM

# è·å–é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.models.quality_gate_model import QualityGateForCausalLM, register_quality_gate


def compare_state_dicts(qwen3_dict, quality_gate_dict, tolerance=1e-6):
    """
    æ¯”è¾ƒ Qwen3 å’Œ Quality-Gate æ¨¡å‹çš„ state_dict

    Args:
        qwen3_dict: Qwen3 æ¨¡å‹çš„ state_dict
        quality_gate_dict: Quality-Gate æ¨¡å‹çš„ state_dict
        tolerance: æ•°å€¼æ¯”è¾ƒçš„å®¹å·®

    Returns:
        dict: è¯¦ç»†çš„æ¯”è¾ƒç»“æœ
    """
    results = {
        "identical_keys": [],  # å®Œå…¨åŒ¹é…çš„æƒé‡
        "missing_in_quality_gate": [],  # Quality-Gate ä¸­ç¼ºå¤±çš„æƒé‡
        "extra_in_quality_gate": [],  # Quality-Gate ä¸­é¢å¤–çš„æƒé‡
        "shape_mismatch": [],  # å½¢çŠ¶ä¸åŒ¹é…
        "value_mismatch": [],  # æ•°å€¼ä¸åŒ¹é…
        "quality_gates": [],  # è´¨é‡é—¨æ§å‚æ•°è¯¦æƒ…
    }

    # 1. æ£€æŸ¥ Qwen3 çš„æ¯ä¸ªæƒé‡åœ¨ Quality-Gate ä¸­æ˜¯å¦å­˜åœ¨ä¸”åŒ¹é…
    for key in qwen3_dict.keys():
        if key not in quality_gate_dict:
            results["missing_in_quality_gate"].append(key)
            continue

        qwen3_tensor = qwen3_dict[key]
        quality_gate_tensor = quality_gate_dict[key]

        # æ£€æŸ¥å½¢çŠ¶
        if qwen3_tensor.shape != quality_gate_tensor.shape:
            results["shape_mismatch"].append({"key": key, "qwen3_shape": qwen3_tensor.shape, "quality_gate_shape": quality_gate_tensor.shape})
            continue

        # æ£€æŸ¥æ•°å€¼
        if torch.allclose(qwen3_tensor, quality_gate_tensor, atol=tolerance):
            results["identical_keys"].append(key)
        else:
            max_diff = torch.max(torch.abs(qwen3_tensor - quality_gate_tensor)).item()
            mean_diff = torch.mean(torch.abs(qwen3_tensor - quality_gate_tensor)).item()
            results["value_mismatch"].append({"key": key, "max_diff": max_diff, "mean_diff": mean_diff, "shape": qwen3_tensor.shape})

    # 2. æ£€æŸ¥ Quality-Gate ä¸­çš„é¢å¤–æƒé‡ï¼ˆåº”è¯¥åªæœ‰è´¨é‡é—¨æ§ï¼‰
    qwen3_keys = set(qwen3_dict.keys())
    quality_gate_keys = set(quality_gate_dict.keys())
    extra_keys = quality_gate_keys - qwen3_keys

    for key in sorted(extra_keys):
        if "quality_gate" in key:
            tensor = quality_gate_dict[key]
            results["quality_gates"].append(
                {
                    "key": key,
                    "shape": tensor.shape,
                    "dtype": str(tensor.dtype),
                    "mean": tensor.mean().item(),
                    "std": tensor.std().item(),
                    "min": tensor.min().item(),
                    "max": tensor.max().item(),
                }
            )
        else:
            # ä¸åº”è¯¥æœ‰è´¨é‡é—¨æ§ä»¥å¤–çš„é¢å¤–å‚æ•°
            results["extra_in_quality_gate"].append(key)

    return results


def compare_models(
    qwen3_model_name="Qwen/Qwen3-1.7B",
    quality_gate_model_path="./converted_models/quality_gate_Qwen3-1.7B",
    device="cpu",
    dtype="bfloat16",
    memory_efficient=True,
):
    """
    æ¯”è¾ƒ Qwen3 æ¨¡å‹å’Œè½¬æ¢åçš„ Quality-Gate æ¨¡å‹

    Args:
        qwen3_model_name: Qwen3 æ¨¡å‹åç§°æˆ–è·¯å¾„
        quality_gate_model_path: Quality-Gate æ¨¡å‹è·¯å¾„
        device: è®¾å¤‡
        dtype: æ•°æ®ç±»å‹
        memory_efficient: æ˜¯å¦ä½¿ç”¨å†…å­˜é«˜æ•ˆæ¨¡å¼
    """
    print("=" * 80)
    print("Qwen3 â†” Quality-Gate æ¨¡å‹è½¬æ¢éªŒè¯")
    print(f"åŸå§‹æ¨¡å‹: {qwen3_model_name}")
    print(f"è½¬æ¢æ¨¡å‹: {quality_gate_model_path}")
    print(f"è®¾å¤‡: {device}")
    print(f"æ•°æ®ç±»å‹: {dtype}")
    print("=" * 80)

    # è½¬æ¢ dtype
    dtype_map = {"float32": torch.float32, "bfloat16": torch.bfloat16, "float16": torch.float16}
    torch_dtype = dtype_map.get(dtype, torch.bfloat16)

    # æ³¨å†Œ Quality-Gate æ¨¡å‹
    register_quality_gate()
    print("âœ“ Quality-Gate æ¨¡å‹å·²æ³¨å†Œ")

    # æ˜¾ç¤º GPU å†…å­˜ä¿¡æ¯
    if device != "cpu" and torch.cuda.is_available():
        total_memory = torch.cuda.get_device_properties(device).total_memory / 1024**3
        print(f"GPU å†…å­˜: {total_memory:.1f} GB")

    try:
        # 1. åŠ è½½åŸå§‹ Qwen3 æ¨¡å‹
        print(f"\nã€æ­¥éª¤ 1ã€‘åŠ è½½åŸå§‹ Qwen3 æ¨¡å‹")
        print(f"æ¨¡å‹: {qwen3_model_name}")
        print("æ­£åœ¨åŠ è½½ï¼Œè¯·ç¨å€™...")

        qwen3_model = AutoModelForCausalLM.from_pretrained(
            qwen3_model_name, torch_dtype=torch_dtype, device_map=device if device != "cpu" else None, low_cpu_mem_usage=True
        )
        qwen3_config = qwen3_model.config

        print("âœ“ Qwen3 æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"  æ¨¡å‹ç±»å‹: {type(qwen3_model).__name__}")
        print(f"  å±‚æ•°: {qwen3_config.num_hidden_layers}")
        print(f"  éšè—å±‚å¤§å°: {qwen3_config.hidden_size}")
        print(f"  è¯æ±‡è¡¨å¤§å°: {qwen3_config.vocab_size}")
        print(f"  æ€»å‚æ•°é‡: {sum(p.numel() for p in qwen3_model.parameters()):,}")

        # æå– state_dict
        if memory_efficient:
            print("  å†…å­˜é«˜æ•ˆæ¨¡å¼: æå– state_dict åé‡Šæ”¾ GPU å†…å­˜")
            qwen3_state_dict = qwen3_model.state_dict()
            qwen3_model = qwen3_model.cpu()
            if device != "cpu":
                torch.cuda.empty_cache()
        else:
            qwen3_state_dict = qwen3_model.state_dict()

        print(f"  State dict å¤§å°: {len(qwen3_state_dict)} ä¸ªå‚æ•°")

        # 2. åŠ è½½ Quality-Gate æ¨¡å‹
        print(f"\nã€æ­¥éª¤ 2ã€‘åŠ è½½è½¬æ¢åçš„ Quality-Gate æ¨¡å‹")
        print(f"æ¨¡å‹è·¯å¾„: {quality_gate_model_path}")

        # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(quality_gate_model_path):
            print(f"âŒ é”™è¯¯: æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {quality_gate_model_path}")
            print("   è¯·å…ˆè¿è¡Œ scripts/convert_qwen_to_quality_gate.py è¿›è¡Œæ¨¡å‹è½¬æ¢")
            return False

        quality_gate_model = QualityGateForCausalLM.from_pretrained(quality_gate_model_path, torch_dtype=torch_dtype, low_cpu_mem_usage=True)

        if device != "cpu":
            quality_gate_model = quality_gate_model.to(device)

        quality_gate_config = quality_gate_model.config

        print("âœ“ Quality-Gate æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"  æ¨¡å‹ç±»å‹: {type(quality_gate_model).__name__}")
        print(f"  é…ç½®ç±»å‹: {type(quality_gate_config).__name__}")
        print(f"  å±‚æ•°: {quality_gate_config.num_hidden_layers}")
        print(f"  æ€»å‚æ•°é‡: {sum(p.numel() for p in quality_gate_model.parameters()):,}")
        print(f"  è´¨é‡é—¨æ§åˆå§‹åŒ–: mean={quality_gate_config.quality_gate_init_mean}, std={quality_gate_config.quality_gate_init_std}")

        quality_gate_state_dict = quality_gate_model.state_dict()
        print(f"  State dict å¤§å°: {len(quality_gate_state_dict)} ä¸ªå‚æ•°")

        # 3. æ¯”è¾ƒ state_dict
        print(f"\nã€æ­¥éª¤ 3ã€‘æ¯”è¾ƒæ¨¡å‹æƒé‡")
        print(f"æ•°å€¼å®¹å·®: {1e-6 if dtype == 'bfloat16' else 1e-8}")

        tolerance = 1e-6 if dtype == "bfloat16" else 1e-8
        results = compare_state_dicts(qwen3_state_dict, quality_gate_state_dict, tolerance)

        # è¾“å‡ºæ¯”è¾ƒç»“æœ
        print("\n" + "â”€" * 80)
        print("æƒé‡æ¯”è¾ƒç»“æœ")
        print("â”€" * 80)

        total_qwen3_params = len(qwen3_state_dict)
        identical_count = len(results["identical_keys"])
        quality_gate_count = len(results["quality_gates"])

        print(f"âœ“ å®Œå…¨åŒ¹é…çš„æƒé‡: {identical_count}/{total_qwen3_params}")
        print(f"âœ“ æ–°å¢è´¨é‡é—¨æ§å‚æ•°: {quality_gate_count}")

        # æ˜¾ç¤ºéƒ¨åˆ†åŒ¹é…çš„æƒé‡ï¼ˆç¤ºä¾‹ï¼‰
        if results["identical_keys"]:
            print("\n  åŒ¹é…æƒé‡ç¤ºä¾‹:")
            for key in results["identical_keys"][:3]:
                print(f"    âœ“ {key}")
            if len(results["identical_keys"]) > 3:
                print(f"    ... è¿˜æœ‰ {len(results['identical_keys']) - 3} ä¸ª")

        # æ£€æŸ¥æ˜¯å¦æœ‰é—®é¢˜
        has_issues = False

        if results["missing_in_quality_gate"]:
            has_issues = True
            print(f"\nâŒ Quality-Gate ä¸­ç¼ºå¤±çš„æƒé‡: {len(results['missing_in_quality_gate'])}")
            for key in results["missing_in_quality_gate"][:5]:
                print(f"    - {key}")
            if len(results["missing_in_quality_gate"]) > 5:
                print(f"    ... è¿˜æœ‰ {len(results['missing_in_quality_gate']) - 5} ä¸ª")

        if results["shape_mismatch"]:
            has_issues = True
            print(f"\nâŒ å½¢çŠ¶ä¸åŒ¹é…: {len(results['shape_mismatch'])}")
            for item in results["shape_mismatch"][:5]:
                print(f"    - {item['key']}")
                print(f"      Qwen3: {item['qwen3_shape']} â†’ Quality-Gate: {item['quality_gate_shape']}")

        if results["value_mismatch"]:
            has_issues = True
            print(f"\nâŒ æ•°å€¼ä¸åŒ¹é…: {len(results['value_mismatch'])}")
            for item in results["value_mismatch"][:5]:
                print(f"    - {item['key']}: max_diff={item['max_diff']:.2e}, mean_diff={item['mean_diff']:.2e}")

        if results["extra_in_quality_gate"]:
            has_issues = True
            print(f"\nâš ï¸  é¢å¤–çš„éè´¨é‡é—¨æ§å‚æ•°: {len(results['extra_in_quality_gate'])}")
            for key in results["extra_in_quality_gate"][:5]:
                print(f"    - {key}")

        # 4. è´¨é‡é—¨æ§å‚æ•°åˆ†æ
        print("\n" + "â”€" * 80)
        print("è´¨é‡é—¨æ§å‚æ•°åˆ†æ")
        print("â”€" * 80)

        if results["quality_gates"]:
            print(f"è´¨é‡é—¨æ§å±‚æ•°: {len(results['quality_gates'])}")
            print(f"é¢„æœŸå±‚æ•°: {qwen3_config.num_hidden_layers}")

            if len(results["quality_gates"]) != qwen3_config.num_hidden_layers:
                has_issues = True
                print(f"âŒ è´¨é‡é—¨æ§å±‚æ•°ä¸åŒ¹é…!")

            # æ˜¾ç¤ºå‰2ä¸ªè´¨é‡é—¨æ§çš„è¯¦ç»†ä¿¡æ¯
            print("\nè´¨é‡é—¨æ§å‚æ•°è¯¦æƒ…:")
            for item in results["quality_gates"][:2]:
                print(f"  {item['key']}")
                print(f"    å½¢çŠ¶: {item['shape']}")
                print(f"    ç»Ÿè®¡: mean={item['mean']:.6f}, std={item['std']:.6f}")
                print(f"    èŒƒå›´: [{item['min']:.6f}, {item['max']:.6f}]")

            if len(results["quality_gates"]) > 2:
                print(f"  ... è¿˜æœ‰ {len(results['quality_gates']) - 2} ä¸ªè´¨é‡é—¨æ§")

            # éªŒè¯åˆå§‹åŒ–æ˜¯å¦ç¬¦åˆé¢„æœŸ
            expected_mean = quality_gate_config.quality_gate_init_mean
            expected_std = quality_gate_config.quality_gate_init_std
            print(f"\nåˆå§‹åŒ–éªŒè¯:")
            print(f"  é…ç½®çš„åˆå§‹åŒ–: mean={expected_mean}, std={expected_std}")

            actual_means = [item["mean"] for item in results["quality_gates"]]
            actual_stds = [item["std"] for item in results["quality_gates"]]
            avg_mean = sum(actual_means) / len(actual_means)
            avg_std = sum(actual_stds) / len(actual_stds)

            print(f"  å®é™…å¹³å‡å€¼: mean={avg_mean:.6f}, std={avg_std:.6f}")

            # æ£€æŸ¥æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
            mean_ok = abs(avg_mean - expected_mean) < 0.1
            std_ok = abs(avg_std - expected_std) < 0.1
            print(f"  å‡å€¼æ£€æŸ¥: {'âœ“' if mean_ok else 'âŒ'}")
            print(f"  æ ‡å‡†å·®æ£€æŸ¥: {'âœ“' if std_ok else 'âŒ'}")

            if not (mean_ok and std_ok):
                has_issues = True

        else:
            has_issues = True
            print("âŒ æœªæ‰¾åˆ°è´¨é‡é—¨æ§å‚æ•°")

        # 5. å‰å‘ä¼ æ’­æµ‹è¯•
        print("\n" + "â”€" * 80)
        print("å‰å‘ä¼ æ’­æµ‹è¯•")
        print("â”€" * 80)

        print("åˆ›å»ºæµ‹è¯•è¾“å…¥...")
        batch_size, seq_len = 2, 16
        test_input = torch.randint(0, qwen3_config.vocab_size, (batch_size, seq_len))
        if device != "cpu":
            test_input = test_input.to(device)

        # æµ‹è¯• Qwen3 æ¨¡å‹
        if memory_efficient and device != "cpu":
            print("å°† Qwen3 æ¨¡å‹ç§»å› GPU...")
            qwen3_model = qwen3_model.to(device)

        print("\næµ‹è¯• Qwen3 æ¨¡å‹...")
        with torch.no_grad():
            qwen3_outputs = qwen3_model(test_input)
            print(f"âœ“ Qwen3 è¾“å‡ºå½¢çŠ¶: {qwen3_outputs.logits.shape}")

        # æµ‹è¯• Quality-Gate æ¨¡å‹
        print("\næµ‹è¯• Quality-Gate æ¨¡å‹ï¼ˆä¸è¾“å‡º router_logitsï¼‰...")
        with torch.no_grad():
            quality_gate_outputs = quality_gate_model(test_input, output_router_logits=False)
            print(f"âœ“ Quality-Gate è¾“å‡ºå½¢çŠ¶: {quality_gate_outputs.logits.shape}")

        # æ¯”è¾ƒè¾“å‡ºæ˜¯å¦ä¸€è‡´
        print("\næ¯”è¾ƒæ¨¡å‹è¾“å‡ºä¸€è‡´æ€§...")
        logits_match = torch.allclose(qwen3_outputs.logits, quality_gate_outputs.logits, atol=1e-3, rtol=1e-3)
        max_logits_diff = torch.max(torch.abs(qwen3_outputs.logits - quality_gate_outputs.logits)).item()
        print(f"  è¾“å‡ºæ˜¯å¦åŒ¹é…: {'âœ“' if logits_match else 'âŒ'}")
        print(f"  æœ€å¤§å·®å¼‚: {max_logits_diff:.2e}")

        if not logits_match:
            has_issues = True
            print("  âš ï¸  è¾“å‡ºä¸å®Œå…¨ä¸€è‡´ï¼Œä½†å°å·®å¼‚å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼ˆç”±äºæ•°å€¼ç²¾åº¦ï¼‰")

        # æµ‹è¯• router_logits è¾“å‡º
        print("\næµ‹è¯• Quality-Gate æ¨¡å‹ï¼ˆè¾“å‡º router_logitsï¼‰...")
        with torch.no_grad():
            quality_gate_outputs_with_router = quality_gate_model(test_input, output_router_logits=True)
            print(f"âœ“ è¾“å‡ºå½¢çŠ¶: {quality_gate_outputs_with_router.logits.shape}")

            if hasattr(quality_gate_outputs_with_router, "router_logits") and quality_gate_outputs_with_router.router_logits:
                router_logits = quality_gate_outputs_with_router.router_logits
                print(f"âœ“ Router logits å·²è¾“å‡º")
                print(f"  å±‚æ•°: {len(router_logits)}")
                print(f"  ç¬¬ä¸€å±‚å½¢çŠ¶: {router_logits[0].shape}")
                print(f"  é¢„æœŸå½¢çŠ¶: [batch_size={batch_size}, seq_len={seq_len}, 1]")

                # éªŒè¯å½¢çŠ¶
                expected_shape = (batch_size, seq_len, 1)
                actual_shape = router_logits[0].shape
                shape_ok = actual_shape == expected_shape
                print(f"  å½¢çŠ¶æ£€æŸ¥: {'âœ“' if shape_ok else 'âŒ'}")

                if not shape_ok:
                    has_issues = True
            else:
                has_issues = True
                print("âŒ Router logits æœªæ‰¾åˆ°")

        # æ¸…ç†å†…å­˜
        if memory_efficient and device != "cpu":
            print("\næ¸…ç† GPU å†…å­˜...")
            del qwen3_model, quality_gate_model
            torch.cuda.empty_cache()
            print("âœ“ å†…å­˜å·²æ¸…ç†")

        # 6. æœ€ç»ˆæ€»ç»“
        print("\n" + "=" * 80)
        print("éªŒè¯æ€»ç»“")
        print("=" * 80)

        print(f"\nåŸºç¡€æƒé‡:")
        print(f"  Qwen3 å‚æ•°æ€»æ•°: {total_qwen3_params}")
        print(f"  å®Œå…¨åŒ¹é…: {identical_count}/{total_qwen3_params} ({100 * identical_count / total_qwen3_params:.1f}%)")

        print(f"\nè´¨é‡é—¨æ§:")
        print(f"  æ–°å¢å‚æ•°æ•°é‡: {quality_gate_count}")
        print(f"  é¢„æœŸå±‚æ•°: {qwen3_config.num_hidden_layers}")
        print(f"  å±‚æ•°æ£€æŸ¥: {'âœ“' if quality_gate_count == qwen3_config.num_hidden_layers else 'âŒ'}")

        print(f"\nå‰å‘ä¼ æ’­:")
        print(f"  åŸºç¡€è¾“å‡ºä¸€è‡´æ€§: {'âœ“' if logits_match else 'âš ï¸'}")
        print(f"  Router logits: {'âœ“' if hasattr(quality_gate_outputs_with_router, 'router_logits') else 'âŒ'}")

        # åˆ¤æ–­æ˜¯å¦é€šè¿‡
        success = (
            identical_count == total_qwen3_params  # æ‰€æœ‰ Qwen3 æƒé‡éƒ½åŒ¹é…
            and len(results["missing_in_quality_gate"]) == 0  # æ²¡æœ‰ç¼ºå¤±
            and len(results["shape_mismatch"]) == 0  # æ²¡æœ‰å½¢çŠ¶ä¸åŒ¹é…
            and len(results["value_mismatch"]) == 0  # æ²¡æœ‰æ•°å€¼ä¸åŒ¹é…
            and len(results["extra_in_quality_gate"]) == 0  # æ²¡æœ‰é¢å¤–å‚æ•°
            and quality_gate_count == qwen3_config.num_hidden_layers  # è´¨é‡é—¨æ§å±‚æ•°æ­£ç¡®
            and hasattr(quality_gate_outputs_with_router, "router_logits")  # router_logits å¯ç”¨
        )

        print("\n" + "=" * 80)
        if success:
            print("ğŸ‰ éªŒè¯é€šè¿‡ï¼è½¬æ¢åçš„æ¨¡å‹å®Œå…¨æ­£ç¡®")
            print("=" * 80)
            print("\nâœ… æ‰€æœ‰æ£€æŸ¥é¡¹:")
            print("   âœ“ Qwen3 åŸºç¡€æƒé‡å®Œå…¨åŒ¹é…")
            print("   âœ“ è´¨é‡é—¨æ§å±‚æ•°æ­£ç¡®")
            print("   âœ“ è´¨é‡é—¨æ§å‚æ•°åˆå§‹åŒ–æ­£ç¡®")
            print("   âœ“ æ— ç¼ºå¤±æˆ–é¢å¤–å‚æ•°")
            print("   âœ“ å‰å‘ä¼ æ’­æ­£å¸¸")
            print("   âœ“ Router logits è¾“å‡ºæ­£ç¡®")
            print("\næ¨¡å‹å·²å¯ç”¨äºè®­ç»ƒï¼")
        else:
            print("âŒ éªŒè¯å¤±è´¥ï¼å‘ç°é—®é¢˜")
            print("=" * 80)
            if has_issues:
                print("\nè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ï¼Œå¯èƒ½éœ€è¦é‡æ–°è½¬æ¢æ¨¡å‹")

        return success

    except Exception as e:
        print(f"\nâŒ éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="éªŒè¯ Qwen3 â†’ Quality-Gate æ¨¡å‹è½¬æ¢çš„æ­£ç¡®æ€§", epilog="å»ºè®®åœ¨è½¬æ¢æ¨¡å‹åç«‹å³è¿è¡Œæ­¤è„šæœ¬è¿›è¡ŒéªŒè¯")

    parser.add_argument("--qwen3-model", type=str, default="Qwen/Qwen3-1.7B", help="åŸå§‹ Qwen3 æ¨¡å‹åç§°æˆ–è·¯å¾„")
    parser.add_argument(
        "--quality-gate-model",
        type=str,
        default="./converted_models/quality_gate_Qwen3-1.7B",
        help="è½¬æ¢åçš„ Quality-Gate æ¨¡å‹è·¯å¾„",
    )
    parser.add_argument("--device", type=str, default="cpu", help="è®¾å¤‡ (cpu, cuda, cuda:0 ç­‰)")
    parser.add_argument("--dtype", type=str, default="bfloat16", choices=["float32", "bfloat16", "float16"], help="æ•°æ®ç±»å‹")
    parser.add_argument("--memory-efficient", action="store_true", help="ä½¿ç”¨å†…å­˜é«˜æ•ˆæ¨¡å¼ï¼ˆé¡ºåºåŠ è½½æ¨¡å‹ï¼‰")

    args = parser.parse_args()

    # éªŒè¯è®¾å¤‡
    if args.device != "cpu" and not torch.cuda.is_available():
        print("âš ï¸  CUDA ä¸å¯ç”¨ï¼Œå›é€€åˆ° CPU")
        args.device = "cpu"

    print("é…ç½®:")
    print(f"  Qwen3 æ¨¡å‹: {args.qwen3_model}")
    print(f"  Quality-Gate æ¨¡å‹: {args.quality_gate_model}")
    print(f"  è®¾å¤‡: {args.device}")
    print(f"  æ•°æ®ç±»å‹: {args.dtype}")
    print(f"  å†…å­˜é«˜æ•ˆæ¨¡å¼: {args.memory_efficient}")

    try:
        success = compare_models(
            qwen3_model_name=args.qwen3_model,
            quality_gate_model_path=args.quality_gate_model,
            device=args.device,
            dtype=args.dtype,
            memory_efficient=args.memory_efficient,
        )
        return success
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
