下面是一份「在**原有任务（以 gsm8k 为例）**基础上创建**自定义任务**」的可操作手册。覆盖两条路线：

1. **切片法（保留 train，仅裁剪 test）** —— 复用 Hub 数据集，不落地文件；
2. **data_files 固化法** —— 把子集写成本地文件，最强复现。

两种方式都**不需要写 Python 代码**，只改 YAML 即可；并且**完全保留原 YAML 的 few-shot 设置**（例如 `fewshot_split: train`、`num_fewshot: 5`）。

---

# 一、前置准备（一次性）

* 建议将你的自定义 YAML 放在单独目录，例如：`eval_tasks/gsm8k/`。运行时用 `--include_path` 指向该目录，Harness 会自动加载这里的任务定义。此做法见官方“New Task Guide/Task Guide”。([GitHub][1])
* 你现有的官方 `gsm8k.yaml` 内容保持不动，**复制**一份做派生（避免污染内置任务）。

---

# 二、方法 A：切片法（Hub 上直接裁剪 test）

> 目标：保留 `train` 以供 few-shot 取样，只让 `test` 用前 N 条（或一个比例）。
> 核心点：把 `dataset_kwargs.split` 写成**字典**，让 `load_dataset` 返回 **DatasetDict**（含 `train` 与裁剪后的 `test`），否则用字符串 `split: "test[:100]"` 会只返回单个 Dataset，导致 `fewshot_split: train` 找不到 `train` 键。([Hugging Face][2])

## A1. 新建 YAML（示例：只评测 test 的前 100 条）

文件：`eval_tasks/gsm8k/gsm8k_head100.yaml`

```yaml
tag:
  - math_word_problems
task: gsm8k_head100

# 与原版一致（保持来源数据相同）
dataset_path: gsm8k
dataset_name: main

# 关键：split 用“字典”写法，保留 train，裁剪 test
dataset_kwargs:
  split:
    train: train
    test: test[:100]

output_type: generate_until

# 保持原有 few-shot 设定（示例沿用你原 YAML）
training_split: train
fewshot_split: train
test_split: test

doc_to_text: "Question: {{question}}\nAnswer:"
doc_to_target: "{{answer}}"

metric_list:
  - metric: exact_match
    aggregation: mean
    higher_is_better: true
    ignore_case: true
    ignore_punctuation: false
    regexes_to_ignore:
      - ","
      - "\\$"
      - "(?s).*#### "
      - "\\.$"

generation_kwargs:
  until:
    - "Question:"
    - "</s>"
    - "<|im_end|>"
  do_sample: false
  temperature: 0.0

repeats: 1
num_fewshot: 5

filter_list:
  - name: "strict-match"
    filter:
      - function: "regex"
        regex_pattern: "#### (\\-?[0-9\\.\\,]+)"
      - function: "take_first"
  - name: "flexible-extract"
    filter:
      - function: "regex"
        group_select: -1
        regex_pattern: "(-?[$0-9.,]{2,})|(-?[0-9]+)"
      - function: "take_first"

metadata:
  version: 3.0
```

> 为何必须是“字典式 split”而不是 `"test[:100]"`？
> 因为 `datasets.load_dataset(path, name, split=...)`：
>
> * `split` 传**字符串** → 返回**单个 Dataset**；
> * **不传**或传**映射（字典）** → 返回**DatasetDict**，包含各 split。lm-eval 的 few-shot 流程会访问 `dataset["train"]`，因此必须让 `train` 存在。([Hugging Face][2])

## A2. 运行命令

```bash
lm_eval --model vllm \
  --model_args "pretrained=Qwen/Qwen2.5-0.5B,dtype=bfloat16" \
  --tasks gsm8k_head100 \
  --include_path eval_tasks/gsm8k \
  --batch_size auto \
  --output_path outputs/stage_4_eval
```

> 备注：`--include_path` 用于告诉 harness 去哪里找你的自定义 YAML 任务。([GitHub][1])

## A3. 变体（区间 / 比例）

* 前 20%：`test[:20%]`
* 跳过前 1000 条：`test[1000:]`
* 任意区间：`test[100:500]`
  这些都是 Hugging Face Datasets 的切片语法，写在**字典式 split 的 `test:` 值**里即可。([Hugging Face][2])

## A4. 常见报错与修复

* **`ValueError: Column 'train' doesn't exist.`**
  多因 `split: "test[:N]"` 使返回值变成单个 Dataset。改为上面的**字典式 split**即可（保留 `train`，裁剪 `test`）。([Hugging Face][2])

---

# 三、方法 B：data_files 固化法（本地文件，最强复现）

> 目标：把“想评测的子集”固定成文件，YAML 通过 `dataset_path: json` + `dataset_kwargs.data_files` 指过去。Harness 会把 `dataset_kwargs` 原样传给 `datasets.load_dataset`，这是官方支持的路径。([slyracoon23.github.io][3])

## B1. 准备两份文件（示例）

* `~/data/gsm8k_train.jsonl`（完整 train，用于 few-shot）
* `~/data/gsm8k_test_head100.jsonl`（裁剪后的 test 子集）

> 文件结构需与模板字段匹配（这里沿用官方 gsm8k 的 `question` / `answer`）。如果你的文件很多，也可用通配或目录。`data_files` 支持字符串、列表、以及带 `train` / `test` 键的**映射**。([Hugging Face][2])

## B2. 新建 YAML

文件：`eval_tasks/gsm8k/gsm8k_fixed_head100.yaml`

```yaml
tag:
  - math_word_problems
task: gsm8k_fixed_head100

# 关键：使用通用 json 加载器 + data_files
dataset_path: json
dataset_name: null
dataset_kwargs:
  data_files:
    train: /home/you/data/gsm8k_train.jsonl
    test:  /home/you/data/gsm8k_test_head100.jsonl

output_type: generate_until

# 继续沿用原任务的 few-shot 设定
training_split: train
fewshot_split: train
test_split: test

doc_to_text: "Question: {{question}}\nAnswer:"
doc_to_target: "{{answer}}"

metric_list:
  - metric: exact_match
    aggregation: mean
    higher_is_better: true
    ignore_case: true
    ignore_punctuation: false
    regexes_to_ignore:
      - ","
      - "\\$"
      - "(?s).*#### "
      - "\\.$"

generation_kwargs:
  until: ["Question:", "</s>", "<|im_end|>"]
  do_sample: false
  temperature: 0.0

repeats: 1
num_fewshot: 5

filter_list:
  - name: "strict-match"
    filter:
      - function: "regex"
        regex_pattern: "#### (\\-?[0-9\\.\\,]+)"
      - function: "take_first"
  - name: "flexible-extract"
    filter:
      - function: "regex"
        group_select: -1
        regex_pattern: "(-?[$0-9.,]{2,})|(-?[0-9]+)"
      - function: "take_first"

metadata:
  version: 3.0
```

## B3. 运行命令

```bash
lm_eval --model vllm \
  --model_args "pretrained=Qwen/Qwen2.5-0.5B,dtype=bfloat16" \
  --tasks gsm8k_fixed_head100 \
  --include_path eval_tasks/gsm8k \
  --batch_size auto \
  --output_path outputs/stage_4_eval
```

## B4. 扩展：同时定义验证与测试

若你想在**同一个 YAML** 内并行定义验证+测试（都来自本地文件），只需：

```yaml
dataset_kwargs:
  data_files:
    train:      /home/you/data/gsm8k_train.jsonl
    validation: /home/you/data/gsm8k_val_tail.jsonl
    test:       /home/you/data/gsm8k_test_head100.jsonl

validation_split: validation
test_split: test
```

这同样是 `datasets.load_dataset("json", data_files=... )` 的标准用法。([Hugging Face][2])

---

# 四、如何验证你的自定义任务

* **列出任务检查是否被识别：**

  ```bash
  lm_eval --tasks list | grep gsm8k_
  ```
* **小样本试跑（不改 YAML）：**

  ```bash
  lm_eval --model vllm --model_args "pretrained=..." \
    --tasks gsm8k_head100 --include_path eval_tasks/gsm8k \
    --limit 5 --num_fewshot 5
  ```

  `--limit` 只是在**推理时**再做一道上限，用来快速冒烟；真实子集边界仍由你的 YAML 决定。任务/参数优先级与加载方式详见官方文档。([GitHub][1])
* **遇到 `Column 'train' doesn't exist`：**
  检查 `dataset_kwargs.split` 是否为**字典**并含 `train`；若你把 `split` 设成了 `"test[:N]"` 的**字符串**，请改为映射写法。([Hugging Face][2])

---

# 五、何时选哪一种？

* **方法 A（切片法）**：最省事、无需写文件；适合快速试验或频繁调整区间/比例。
* **方法 B（data_files 固化法）**：最可复现、便于审计和协作；适合需要长期复用同一批样本的评测。

---

# 六、速查卡（Cheat Sheet）

* **保持 few-shot 不变但裁剪 test：**

  ```yaml
  dataset_kwargs:
    split:
      train: train
      test: test[:100]
  ```

  （保留 `train` 键是关键。）([Hugging Face][2])

* **用本地文件固定训练/验证/测试：**

  ```yaml
  dataset_path: json
  dataset_kwargs:
    data_files:
      train: /path/train.jsonl
      validation: /path/val.jsonl
      test: /path/test.jsonl
  validation_split: validation
  test_split: test
  ```

  （`dataset_kwargs` 会原样传给 `load_dataset`，支持 `data_files`、`data_dir` 等参数。）([slyracoon23.github.io][3])

* **加载自定义任务目录：**

  ```bash
  lm_eval ... --include_path /path/to/your/task_dir
  ```

  （见官方 New Task/Task Guide。）([GitHub][1])

---

需要我把你的现有 `gsm8k.yaml` 直接改成两份可用模板（`head100` + `tail-rest`）吗？我可以按你想要的具体切分（条数 / 百分比）生成好成品 YAML。

[1]: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md?utm_source=chatgpt.com "lm-evaluation-harness/docs/new_task_guide.md at main - GitHub"
[2]: https://hugging-face.cn/docs/datasets/package_reference/loading_methods?utm_source=chatgpt.com "加载方法 - Hugging Face 文档"
[3]: https://slyracoon23.github.io/lm-evaluation-harness/task_guide/?utm_source=chatgpt.com "Task Guide - LM Evaluation Harness"
