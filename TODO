路由参数的初始化

垃圾专家的输出：为0，随机噪声

基础垃圾桶：为0，随机噪声，恒等映射

loss的约束：根据token长度不同，根据激活比例来看，负载均衡。

LESS是在FLAN V2、CoT、DOLLY、OPEN ASSISTANT 1的四个混合数据集上预热训练的。然后根据不同的任务去进行数据选择。例如：mmlu-chat_adam_sim_trainp0.05_seed3_p0.05，这表示其针对MMLU数据集的chat任务，使用adam优化器，模拟训练集的比例为0.05，随机种子为3。需要从什么数据集中选择数据，就在什么数据集上预热。
在LESS的阶段2，它使用了traker库来对单一训练集获取梯度存储（使用随机投影方法）
在第三步中，它需要指定源训练集和单个目标任务，从而挑选出真正的训练集。

也就是说，如果现在有训练集D1到DN，那么就要把D1到DN的所有数据集都混合得到D，并完成预热训练。
再对D1到DN都获取梯度存储。
根据不同的任务，选择不同的源训练集和目标任务，挑选出真正的训练集。

一个自然而然的疑问是：我们的方法不需要指定任务。如果是同样挑选5%的数据的话，我们会将这5%的数据用于一次训练，然后在多个任务上测试。但LESS会在每个任务上各挑选5%的数据进行训练。如果进行更公平的比较？

目前约束计算的方式是：在top-k个专家中，垃圾桶专家的概率。如果top-k个专家中是没有垃圾专家的，那么trash_can_ratio就是0，约束值最大。不过这里是否应该设置为计算logits分数softmax后得到的概率，而非只从top-k个专家中计算，这样的话即使top-k个专家没有垃圾专家也能让它得到训练。

def custom_constraint_loss(
    router_logits: List[torch.Tensor], config: SelectMoeConfig
) -> torch.Tensor:
    """
    Compute custom constraint loss for trash can experts.

    This loss encourages the model to balance between using real experts and trash can experts
    based on data quality. Higher trash can usage should correlate with lower data quality.
    """
    if len(router_logits) == 0:
        return torch.tensor(
            0.0, device=next(iter(router_logits)).device if router_logits else "cpu"
        )

    total_loss = 0.0
    num_layers = 0

    for layer_router_logits in router_logits:
        if layer_router_logits is None:
            continue

        # Get routing probabilities for all experts
        routing_probs = F.softmax(layer_router_logits, dim=-1)

        # Get top-k routing decisions (actual expert selection)
        top_k_probs, selected_experts = torch.topk(
            routing_probs, k=config.num_experts_per_tok, dim=-1
        )

        # Calculate trash can expert usage ratio
        # Trash can experts are indices >= config.num_experts
        trash_can_mask = selected_experts >= config.num_experts
        trash_can_probs = top_k_probs * trash_can_mask.float()
        trash_can_ratio = trash_can_probs.sum(dim=-1)  # Shape: (batch_size * seq_len,)


        # Beta distribution inspired loss to encourage balanced usage
        # When trash_can_ratio is too low (high quality data): loss increases
        # When trash_can_ratio is too high (low quality data): loss decreases
        alpha = config.trash_can_loss_alpha
        beta = config.trash_can_loss_beta

        # Clamp ratio to avoid log(0)
        ratio_clamped = torch.clamp(trash_can_ratio, min=1e-8, max=1.0 - 1e-8)

        if alpha == 1.0:
            # Simplified form: encourages moderate trash can usage
            layer_loss = -(beta - 1) * torch.log(ratio_clamped) - torch.log(
                1 - ratio_clamped
            )
        else:
            # Full beta distribution form
            layer_loss = -(
                (alpha - 1) * torch.log(ratio_clamped)
                + (beta - 1) * torch.log(1 - ratio_clamped)
            )

        total_loss += layer_loss.mean()
        num_layers += 1

    return total_loss / max(num_layers, 1)



LESS的训练设置：
线性预热，余弦衰减，学习率2e-5，batch size=128，epoch=4，
Lora：r=128, alpha=512, dropout=0.1, attention的所有参数，