# MyGO: using MoE to select your Good and Omnigenous data

## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›® (MyGO) æ˜¯ä¸€ä¸ªåˆ›æ–°çš„æ•°æ®é€‰æ‹©å®éªŒï¼Œæ—¨åœ¨æ¢ç´¢ä¸€ç§åˆ©ç”¨æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMixture-of-Experts, MoEï¼‰è¿›è¡Œé«˜æ•ˆæ•°æ®ç­›é€‰çš„æ–¹æ³•ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

1. **é¢„çƒ­é˜¶æ®µ**: å¯¹å°å‹ Select-MoE æ¨¡å‹çš„ Routerï¼ˆè·¯ç”±å™¨ï¼‰è¿›è¡Œé¢„çƒ­å¾®è°ƒï¼Œä½¿å…¶å…·å¤‡æ•°æ®è´¨é‡åˆ¤åˆ«èƒ½åŠ›
2. **é€‰æ‹©é˜¶æ®µ**: åˆ©ç”¨é¢„çƒ­çš„ Router ä¸ºå¤§è§„æ¨¡æ•°æ®é›†æ‰“åˆ†ï¼Œé€šè¿‡GPUåŠ é€Ÿèšç±»ç®—æ³•ç­›é€‰å¤šæ ·åŒ–é«˜è´¨é‡æ•°æ®å­é›†  
3. **å¾®è°ƒé˜¶æ®µ**: ä½¿ç”¨ç­›é€‰çš„é«˜è´¨é‡æ•°æ®å¾®è°ƒå¤§è§„æ¨¡ç›®æ ‡æ¨¡å‹
4. **è¯„ä¼°é˜¶æ®µ**: è¯„ä¼°æ•°æ®é€‰æ‹©ç­–ç•¥çš„æœ€ç»ˆæ•ˆæœ

## âœ¨ æ ¸å¿ƒåˆ›æ–°

### Select-MoE æ¶æ„ç‰¹æ€§ - **æœ€æ–°æ›´æ–°**
- **ä¸¤å±‚è·¯ç”±æ¶æ„**: å®ç°è´¨é‡é—¨ + MoE + åƒåœ¾ä¸“å®¶çš„å¹¶è¡Œå¤„ç†ç»“æ„
- **ç®€åŒ–è´¨é‡é—¨ (NEW)**: ä¸€çº§è·¯ç”±è¾“å‡ºå•ä¸ªè´¨é‡åˆ†æ•°ï¼Œé€šè¿‡sigmoidå¾—åˆ°good_ratio
  - **æ¶æ„ç®€åŒ–**: ä»2ç±»åˆ†ç±»æ”¹ä¸ºå•åˆ†æ•°è¾“å‡ºï¼Œ`good_ratio = sigmoid(quality_score)`
  - **æ›´å¥½æ¢¯åº¦æµ**: ç›´æ¥å¯¹åŸå§‹åˆ†æ•°åº”ç”¨sigmoidï¼Œé¿å…softmaxçš„æ•°å€¼é—®é¢˜
  - **åŠ¨æ€æ¯”ä¾‹**: `bad_ratio = 1 - good_ratio`ï¼Œç¡®ä¿å®Œç¾äº’è¡¥
- **æ ‡å‡†MoEé›†æˆ**: ä½¿ç”¨æ ‡å‡†OlmoeSparseMoeBlockè¿›è¡Œä¸“å®¶è·¯ç”±ï¼Œä¿æŒåŸå§‹æƒé‡ä¸å˜
- **å¯é…ç½®åƒåœ¾ä¸“å®¶**: æ”¯æŒå¤šç§è¾“å‡ºæ¨¡å¼ï¼ˆé›¶å€¼ã€å™ªå£°ã€è‡ªå®šä¹‰ï¼‰å¤„ç†ä½è´¨é‡æ•°æ®
- **å¢å¼ºæŸå¤±å‡½æ•° (NEW)**: 
  - **å¯æ‰©å±•æ¡†æ¶**: æ”¯æŒå¤šç§æŸå¤±ç±»å‹ (sigmoid, MSE, custom)
  - **å¡«å……ä»¤ç‰Œå¤„ç†**: æ­£ç¡®å¤„ç†attention_maskï¼Œæ’é™¤padding tokens
  - **è‡ªå®šä¹‰æŸå¤±**: æ”¯æŒå®éªŒæ€§æŸå¤±å‡½æ•°ï¼Œä¾¿äºè°ƒè¯•å’Œä¼˜åŒ–
  - **NEW: æ–¹æ¡ˆä¸€ & æ–¹æ¡ˆäºŒ**: å®ç°äº†BetaçŸ©åŒ¹é…å’Œå‡å€¼-æ–¹å·®æ­£åˆ™åŒ–ä¸¤ç§é«˜çº§æŸå¤±å‡½æ•°
  - **å¯é…ç½®è°ƒè¯•**: `quality_loss_debug`å‚æ•°æ”¯æŒè¯¦ç»†çš„æŸå¤±è®¡ç®—è°ƒè¯•è¾“å‡º
- **èšç±»é€‰æ‹©ç®—æ³• (NEW)**: GPUåŠ é€Ÿèšç±»å®ç°å¤šæ ·åŒ–æ•°æ®é€‰æ‹©
  - **K-Means + Elbow Method**: è‡ªåŠ¨kå€¼é€‰æ‹©ï¼Œç¡®ä¿æœ€ä¼˜èšç±»æ•°é‡
  - **HDBSCANèšç±»**: æ— å‚æ•°å¯†åº¦èšç±»ï¼Œè‡ªé€‚åº”å‘ç°ç°‡ç»“æ„
  - **ä½™å¼¦è·ç¦»**: ä½¿ç”¨MoE logitsçš„è¯­ä¹‰ç›¸ä¼¼æ€§è¿›è¡Œèšç±»
  - **è½®é€‰ç­–ç•¥**: ä»æ¯ä¸ªç°‡ä¸­è½®æµé€‰æ‹©é«˜è´¨é‡æ•°æ®ï¼Œä¿è¯å¤šæ ·æ€§
  - **GPUåŠ é€Ÿ**: æ”¯æŒRAPIDS cuMLå’ŒPyTorch GPUåŠ é€Ÿï¼Œå¤„ç†å¤§è§„æ¨¡æ•°æ®
- **HuggingFace å…¼å®¹**: æ”¯æŒæ ‡å‡†çš„ `from_pretrained()` åŠ è½½å’Œç”Ÿæ€å·¥å…·

### æ¶æ„å¯¹æ¯”

| ç‰¹æ€§ | åŸå§‹ç‰ˆæœ¬ | æœ€æ–°ç‰ˆæœ¬ (å½“å‰) |
|------|----------|----------------|
| è´¨é‡é—¨è¾“å‡º | 2ç±»logits | å•ä¸ªåŸå§‹åˆ†æ•° |
| æ¦‚ç‡è®¡ç®— | softmaxå½’ä¸€åŒ– | sigmoidæ¿€æ´» |
| æŸå¤±å‡½æ•° | sigmoid(softmax_prob) | ç›´æ¥sigmoid(raw_score) |
| å¡«å……å¤„ç† | æ— ç‰¹æ®Šå¤„ç† | attention_maskæ’é™¤padding |
| æŸå¤±æ‰©å±•æ€§ | å›ºå®šå‡½æ•° | æ”¯æŒè‡ªå®šä¹‰æŸå¤±å‡½æ•° |
| è°ƒè¯•æ”¯æŒ | åŸºæœ¬ | ä¸°å¯Œçš„å®éªŒæ¡†æ¶ |
| é«˜çº§æŸå¤± | æ—  | BetaçŸ©åŒ¹é… & å‡å€¼-æ–¹å·®æ­£åˆ™åŒ– |
| é…ç½®åŒ–è°ƒè¯• | æ—  | quality_loss_debugå‚æ•° |
| æ•°æ®é€‰æ‹© | åŸºç¡€è´¨é‡ç­›é€‰ | èšç±»+è½®é€‰å¤šæ ·åŒ–é€‰æ‹© |
| èšç±»ç®—æ³• | æ—  | K-Means + HDBSCAN |
| GPUåŠ é€Ÿ | æ—  | RAPIDS cuML + PyTorch |

### æ¨¡å‹å¯¹æ¯”

| ç‰¹æ€§ | åŸå§‹ OLMoE | Select-MoE |
|------|------------|------------|
| MoEä¸“å®¶æ•° | 64 | 64 (ä¿æŒä¸å˜) |
| è´¨é‡é—¨ | æ—  | 2è¾“å‡º (å¥½/ååˆ†ç±») |
| åƒåœ¾ä¸“å®¶ | æ—  | 1ä¸ª (å¯é…ç½®è¾“å‡ºæ¨¡å¼) |
| è·¯ç”±ç»“æ„ | å•å±‚MoE | ä¸¤å±‚ (è´¨é‡é—¨ + MoE) |
| é¢„è®­ç»ƒæƒé‡ | - | MoEæƒé‡å®Œå…¨ä¿æŒ |
| æ•°æ®è´¨é‡é€‰æ‹© | æ—  | åŸºäºè´¨é‡é—¨è¾“å‡º |

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **åŒ…ç®¡ç†**: [`uv`](https://docs.astral.sh/uv/) - å¿«é€Ÿ Python åŒ…ç®¡ç†å™¨
- **æ·±åº¦å­¦ä¹ **: [`torch`](https://pytorch.org/) 2.6.0, [`transformers`](https://github.com/huggingface/transformers)
- **æ¨¡å‹å¾®è°ƒ**: [`peft`](https://github.com/huggingface/peft) - LoRA ç­‰é«˜æ•ˆå¾®è°ƒæ–¹æ³•
- **åˆ†å¸ƒå¼è®­ç»ƒ**: [`accelerate`](https://github.com/huggingface/accelerate) - å¤šGPU è®­ç»ƒæ”¯æŒ
- **é…ç½®ç®¡ç†**: [`hydra`](https://github.com/facebookresearch/hydra) - çµæ´»çš„é…ç½®ç³»ç»Ÿ
- **æ¨¡å‹è¯„ä¼°**: [`lm-eval`](https://github.com/EleutherAI/lm-evaluation-harness) - æ ‡å‡†è¯„æµ‹æ¡†æ¶
- **èšç±»ç®—æ³•**: [`scikit-learn`](https://scikit-learn.org/) - K-Meanså’ŒHDBSCANèšç±»ç®—æ³•
- **GPUèšç±»**: [`RAPIDS cuML`](https://github.com/rapidsai/cuml) - GPUåŠ é€Ÿèšç±» (å¯é€‰)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå‡†å¤‡

```bash
# 1. å®‰è£… uv åŒ…ç®¡ç†å™¨
wget -qO- https://astral.sh/uv/install.sh | sh

# 2. åŒæ­¥é¡¹ç›®ä¾èµ–
uv sync

# 3. (å¯é€‰) é…ç½®å›½å†…é•œåƒæº
./tools/chsrc set uv

# 4. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate
```

### æ•°æ®å‡†å¤‡

```bash
# ä¸‹è½½è®­ç»ƒæ•°æ®é›†
wget https://hf-mirror.com/datasets/princeton-nlp/less_data/resolve/main/less-data.zip
unzip less-data.zip

# ä¸‹è½½è¯„ä¼°æ•°æ®é›†
export HF_ENDPOINT=https://hf-mirror.com
huggingface-cli download hails/mmlu_no_train --repo-type dataset 
huggingface-cli download cais/mmlu --repo-type dataset

# ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
huggingface-cli download allenai/OLMoE-1B-7B-0125
huggingface-cli download meta-llama/Llama-2-7b-hf
huggingface-cli download Qwen/Qwen2.5-1.5B
```

## ğŸ“‹ å®Œæ•´æ‰§è¡Œæµç¨‹

æœ¬é¡¹ç›®åŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼š**æ¨¡å‹è½¬æ¢** å’Œ **å››é˜¶æ®µè®­ç»ƒæµç¨‹**ã€‚

### æ­¥éª¤ 0: æ¨¡å‹è½¬æ¢

é¦–å…ˆéœ€è¦å°† OLMoE é¢„è®­ç»ƒæ¨¡å‹è½¬æ¢ä¸º Select-MoE æ ¼å¼ï¼š

```bash
# åŸºæœ¬è½¬æ¢
python scripts/convert_olmoe_to_select_moe.py \
    --save-path ./converted_models/select_moe_converted_OLMoE-1B-7B-0125

# (å¯é€‰) éªŒè¯è½¬æ¢ç»“æœ
python scripts/compare_converted_model.py \
    --converted-model ./converted_models/select_moe_converted_OLMoE-1B-7B-0125 \
    --dtype bfloat16 \
```

### æ­¥éª¤ 1: é¢„çƒ­è®­ç»ƒ Select-MoE è·¯ç”±æƒé‡

è®­ç»ƒ Select-MoE æ¨¡å‹çš„ Routerï¼Œä½¿å…¶å­¦ä¹ æ•°æ®è´¨é‡åˆ¤åˆ«ï¼š

```bash
# å• GPU è®­ç»ƒ
CUDA_VISIBLE_DEVICES=0 bash scripts/run_stage_1.sh

# å¤š GPU è®­ç»ƒ
CUDA_VISIBLE_DEVICES=0,1,2,3 bash scripts/run_stage_1.sh

# è‡ªå®šä¹‰å‚æ•°è®­ç»ƒ
CUDA_VISIBLE_DEVICES=0 bash scripts/run_stage_1.sh \
    training.learning_rate=5e-5 \
    training.batch_size=8 \
    dataset.subset_ratio=0.1
```

**è¾“å‡º**: æƒé‡æ–‡ä»¶ä¿å­˜åœ¨ `outputs/stage_1_pretrain/YYYY-MM-DD/HH-MM-SS/full_rank_weights.pt`

### æ­¥éª¤ 2: èšç±»æ•°æ®é€‰æ‹©

ä½¿ç”¨é¢„çƒ­çš„ Select-MoE æ¨¡å‹ä¸ºè®­ç»ƒæ•°æ®æ‰“åˆ†å¹¶é€šè¿‡èšç±»ç®—æ³•ç­›é€‰å¤šæ ·åŒ–æ•°æ®ï¼š

```bash
# ä½¿ç”¨é˜¶æ®µ1çš„è¾“å‡ºè¿›è¡Œèšç±»æ•°æ®é€‰æ‹©
CUDA_VISIBLE_DEVICES=0 bash scripts/run_stage_2.sh \
    model_checkpoint_path=outputs/stage_1_pretrain/2025-07-16/01-57-27/full_rank_weights.pt

# è°ƒæ•´é€‰æ‹©æ¯”ä¾‹å’Œèšç±»æ–¹æ³•
CUDA_VISIBLE_DEVICES=0 bash scripts/run_stage_2.sh \
    model_checkpoint_path=outputs/stage_1_pretrain/2025-07-16/01-57-27/full_rank_weights.pt \
    selection_percentage=0.1 \
    clustering_method=hdbscan

# è‡ªå®šä¹‰K-Meanså‚æ•°
CUDA_VISIBLE_DEVICES=0 bash scripts/run_stage_2.sh \
    model_checkpoint_path=outputs/stage_1_pretrain/2025-07-16/01-57-27/full_rank_weights.pt \
    clustering_method=kmeans \
    clustering_params.k_range="[20,80]" \
    clustering_params.max_iters=500

# è‡ªå®šä¹‰HDBSCANå‚æ•°
CUDA_VISIBLE_DEVICES=0 bash scripts/run_stage_2.sh \
    model_checkpoint_path=outputs/stage_1_pretrain/2025-07-16/01-57-27/full_rank_weights.pt \
    clustering_method=hdbscan \
    clustering_params.min_cluster_size=150 \
    clustering_params.auto_tune=true
```

**è¾“å‡º**: èšç±»ç­›é€‰æ•°æ®ä¿å­˜åœ¨ `outputs/stage_2_selection/YYYY-MM-DD/HH-MM-SS/selected_data.jsonl`

### æ­¥éª¤ 3: ç›®æ ‡æ¨¡å‹å¾®è°ƒ

ä½¿ç”¨ç­›é€‰çš„æ•°æ®å¯¹ Llama-2-7B è¿›è¡Œ LoRA å¾®è°ƒï¼š

```bash
# åŸºæœ¬å¾®è°ƒ
CUDA_VISIBLE_DEVICES=0,1,2,3 bash scripts/run_stage_3.sh \
    dataset.data_path=outputs/stage_2_selection/2025-07-17/04-49-54/selected_data.jsonl

# è‡ªå®šä¹‰ LoRA å‚æ•°
CUDA_VISIBLE_DEVICES=0,1 bash scripts/run_stage_3.sh \
    dataset.data_path=outputs/stage_2_selection/2025-07-17/04-49-54/selected_data.jsonl \
    training.lora.r=64 \
    training.lora.lora_alpha=256
```

**è¾“å‡º**: LoRA é€‚é…å™¨ä¿å­˜åœ¨ `outputs/stage_3_finetune/YYYY-MM-DD/HH-MM-SS/checkpoint-XXXX/`

### æ­¥éª¤ 4: æ¨¡å‹è¯„ä¼°

ä½¿ç”¨ `lm-eval` è¯„ä¼°å¾®è°ƒåæ¨¡å‹çš„æ€§èƒ½ï¼š

```bash
# MMLU è¯„ä¼°
CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch -m lm_eval --model hf \
    --model_args pretrained=meta-llama/Llama-2-7b-hf,peft=outputs/stage_3_finetune/2025-07-18/01-01-10/checkpoint-1804 \
    --tasks mmlu \
    --batch_size auto \
    --output_path outputs/stage_4_eval

# å¤šä»»åŠ¡è¯„ä¼°
CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch -m lm_eval --model hf \
    --model_args pretrained=meta-llama/Llama-2-7b-hf,peft=outputs/stage_3_finetune/2025-07-18/01-01-10/checkpoint-1804 \
    --tasks mmlu,hellaswag,arc_easy,arc_challenge \
    --batch_size auto \
    --output_path outputs/stage_4_eval
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### ç¨‹åºåŒ–ä½¿ç”¨ Select-MoE æ¨¡å‹

```python
from src.models.select_moe import SelectMoeForCausalLM, register_select_moe

# æ³¨å†Œ Select-MoEï¼ˆå¿…é¡»åœ¨åŠ è½½å‰æ‰§è¡Œï¼‰
register_select_moe()

# åŠ è½½è½¬æ¢åçš„æ¨¡å‹
model = SelectMoeForCausalLM.from_pretrained("./converted_models/select_moe_converted_OLMoE-1B-7B-0125")

# è®­ç»ƒæ—¶å¼€å¯ router logits
outputs = model(
    input_ids=input_ids,
    attention_mask=attention_mask,
    labels=labels,
    output_router_logits=True  # é‡è¦ï¼šè®­ç»ƒæ—¶å¿…é¡»ä¸ºTrue
)

# æ–°æ¶æ„è¿”å›å­—å…¸æ ¼å¼çš„è·¯ç”±è¾“å‡º (æ›´æ–°åçš„æ ¼å¼)
for layer_output in outputs.router_logits:
    quality_score = layer_output["quality_score"]   # å½¢çŠ¶: [batch, seq_len, 1] - åŸå§‹åˆ†æ•°
    moe_logits = layer_output["moe_logits"]         # å½¢çŠ¶: [batch*seq_len, num_experts]
    
    # æ‰‹åŠ¨è®¡ç®—è´¨é‡æ¯”ä¾‹ (å¦‚æœéœ€è¦)
    good_ratio = torch.sigmoid(quality_score)       # å½¢çŠ¶: [batch, seq_len, 1]
    bad_ratio = 1.0 - good_ratio                    # å½¢çŠ¶: [batch, seq_len, 1]

# æŸå¤±åŒ…å«è¯­è¨€å»ºæ¨¡ + è´Ÿè½½å‡è¡¡ + è´¨é‡åˆ†ç±»æŸå¤±
# æ–°ç‰ˆæœ¬è‡ªåŠ¨å¤„ç†padding tokens
total_loss = outputs.loss

# **NEW**: é…ç½®è´¨é‡æŸå¤±ç±»å‹å’Œè°ƒè¯•
model.config.quality_loss_type = "beta_moment_matching"  # æ–¹æ¡ˆä¸€: BetaçŸ©åŒ¹é…
# model.config.quality_loss_type = "mean_variance_regularization"  # æ–¹æ¡ˆäºŒ: å‡å€¼-æ–¹å·®æ­£åˆ™åŒ–
model.config.quality_loss_debug = True  # å¯ç”¨è°ƒè¯•è¾“å‡º

# **NEW**: é…ç½®è‡ªå®šä¹‰æŸå¤±å‚æ•°
# æ–¹æ¡ˆä¸€å‚æ•° (BetaçŸ©åŒ¹é…)
model.config.beta_target_mean = 0.5
model.config.beta_target_var = 0.05
model.config.w_mean = 1.0
model.config.w_var = 1.0

# æ–¹æ¡ˆäºŒå‚æ•° (å‡å€¼-æ–¹å·®æ­£åˆ™åŒ–)
model.config.lambda_var = 0.1

# è‡ªå®šä¹‰æŸå¤±å‡½æ•°ç¤ºä¾‹ (å®éªŒæ€§åŠŸèƒ½ï¼Œä»ç„¶æ”¯æŒ)
def my_custom_loss(good_ratio, attention_mask):
    # ä½ çš„è‡ªå®šä¹‰æŸå¤±é€»è¾‘
    # è¿”å›å½¢çŠ¶ä¸º (batch_size, seq_len) çš„å¼ é‡
    return torch.pow(good_ratio.squeeze(-1), 2)  # ç¤ºä¾‹ï¼šå¹³æ–¹æŸå¤±

# å¯ä»¥é€šè¿‡ä¿®æ”¹ quality_classification_loss è°ƒç”¨æ¥ä½¿ç”¨è‡ªå®šä¹‰æŸå¤±
```

### æ¶æ„å˜æ›´è¯´æ˜

**é‡è¦å˜æ›´ (2025å¹´æœ€æ–°)**:
- **Routerè¾“å‡ºæ ¼å¼**: `quality_logits` â†’ `quality_score` (å½¢çŠ¶ä» [batch, seq_len, 2] å˜ä¸º [batch, seq_len, 1])
- **æŸå¤±å‡½æ•°å¢å¼º**: æ”¯æŒå¤šç§æŸå¤±ç±»å‹å’Œè‡ªå®šä¹‰æŸå¤±å‡½æ•°
- **Paddingå¤„ç†**: è‡ªåŠ¨æ’é™¤å¡«å……tokenï¼Œæé«˜è®­ç»ƒè´¨é‡
- **è°ƒè¯•å‹å¥½**: ä¸°å¯Œçš„å®éªŒæ¡†æ¶æ”¯æŒï¼Œä¾¿äºæŸå¤±å‡½æ•°è°ƒè¯•
- **NEW: é«˜çº§æŸå¤±å‡½æ•°**: å®ç°æ–¹æ¡ˆä¸€(BetaçŸ©åŒ¹é…)å’Œæ–¹æ¡ˆäºŒ(å‡å€¼-æ–¹å·®æ­£åˆ™åŒ–)
- **NEW: å¯é…ç½®è°ƒè¯•**: `quality_loss_debug` å‚æ•°æ”¯æŒè¯¦ç»†çš„æŸå¤±è®¡ç®—è°ƒè¯•è¾“å‡º
- **NEW: å‚æ•°åŒæ­¥**: æ‰€æœ‰è®­ç»ƒé˜¶æ®µå®Œå…¨åŒæ­¥æ–°çš„é…ç½®å‚æ•°

### å‚æ•°è¦†å†™æœºåˆ¶

é¡¹ç›®ä½¿ç”¨ Hydra é…ç½®ç®¡ç†ï¼Œæ”¯æŒçµæ´»çš„å‘½ä»¤è¡Œå‚æ•°è¦†å†™ï¼š

```bash
# åŸºæœ¬è¯­æ³•
bash scripts/script_name.sh key1=value1 key2.subkey=value2

# å®é™…ç¤ºä¾‹
bash scripts/run_stage_1.sh training.learning_rate=1e-5 dataset.subset_ratio=0.1
bash scripts/run_stage_2.sh selection_percentage=0.1 data_process.batch_size=32
bash scripts/run_stage_3.sh training.lora.r=128 training.batch_size=64
```

## âš™ï¸ é…ç½®è¯´æ˜

### ä¸»è¦é…ç½®æ–‡ä»¶

- `configs/stage_1_pretrain.yaml` - é˜¶æ®µ1é¢„çƒ­è®­ç»ƒé…ç½®
- `configs/stage_2_selection.yaml` - é˜¶æ®µ2æ•°æ®é€‰æ‹©é…ç½®  
- `configs/stage_3_finetune.yaml` - é˜¶æ®µ3æ¨¡å‹å¾®è°ƒé…ç½®
- `configs/stage_4_evaluate.yaml` - é˜¶æ®µ4æ¨¡å‹è¯„ä¼°é…ç½®

### å…³é”®å‚æ•°è¯´æ˜

**é˜¶æ®µ1 (é¢„çƒ­è®­ç»ƒ)**:
- `training.peft_mode`: è®­ç»ƒæ¨¡å¼ (`full_rank` æˆ– `lora`)
- `training.learning_rate`: å­¦ä¹ ç‡ (é»˜è®¤: 1e-4)
- `dataset.subset_ratio`: è®­ç»ƒæ•°æ®æ¯”ä¾‹ (é»˜è®¤: 0.05)
- `training.quality_loss_weight`: è´¨é‡åˆ†ç±»æŸå¤±æƒé‡ (é»˜è®¤: 0.01)
- `training.quality_gate_init_mean/std`: è´¨é‡é—¨åˆå§‹åŒ–å‚æ•°
- `training.trash_expert_mode`: åƒåœ¾ä¸“å®¶æ¨¡å¼ ("zero", "noise", "custom")
- `training.enable_load_balancing`: å¯ç”¨MoEè´Ÿè½½å‡è¡¡æŸå¤±

**é˜¶æ®µ2 (èšç±»æ•°æ®é€‰æ‹©)**:
- `selection_percentage`: æ•°æ®é€‰æ‹©æ¯”ä¾‹ (é»˜è®¤: 0.05)
- `model_checkpoint_path`: é˜¶æ®µ1è¾“å‡ºçš„æƒé‡è·¯å¾„
- `clustering_method`: èšç±»ç®—æ³• ('kmeans' æˆ– 'hdbscan', é»˜è®¤: 'kmeans')
- `clustering_params`: èšç±»å‚æ•°é…ç½®
  - **K-Meanså‚æ•°**: `auto_k`, `k`, `k_range`, `max_iters`
  - **HDBSCANå‚æ•°**: `min_cluster_size`, `min_samples`, `metric`, `use_gpu`, `auto_tune`

**é˜¶æ®µ3 (æ¨¡å‹å¾®è°ƒ)**:
- `training.lora.r`: LoRA ç§© (é»˜è®¤: 128)
- `training.learning_rate`: å­¦ä¹ ç‡ (é»˜è®¤: 2e-5)
- `dataset.data_path`: é˜¶æ®µ2è¾“å‡ºçš„æ•°æ®è·¯å¾„

## ğŸ’¡ é‡è¦æç¤º

### ç¯å¢ƒå˜é‡
æ¯ä¸ªè„šæœ¬æ‰§è¡Œå‰éƒ½éœ€è¦è®¾ç½® `CUDA_VISIBLE_DEVICES`ï¼š
```bash
export CUDA_VISIBLE_DEVICES=0,1,2,3  # æŒ‡å®šä½¿ç”¨çš„GPU
```

### è·¯å¾„ä¾èµ–
æ³¨æ„å„é˜¶æ®µä¹‹é—´çš„è·¯å¾„ä¾èµ–å…³ç³»ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è¾“å…¥è·¯å¾„ï¼š
- é˜¶æ®µ2 éœ€è¦é˜¶æ®µ1 çš„ `full_rank_weights.pt`
- é˜¶æ®µ3 éœ€è¦é˜¶æ®µ2 çš„ `selected_data.jsonl`  
- é˜¶æ®µ4 éœ€è¦é˜¶æ®µ3 çš„ LoRA æ£€æŸ¥ç‚¹

## ğŸ“– è¯¦ç»†æ–‡æ¡£

æ›´å¤šè¯¦ç»†çš„æ‰§è¡Œè¯´æ˜å’Œå‚æ•°é…ç½®ï¼Œè¯·å‚è€ƒ [`docs.md`](docs.md) æ–‡ä»¶ã€‚

## ğŸ”¬ æŠ€æœ¯åŸç†

### èšç±»-è½®é€‰æ•°æ®é€‰æ‹©ç­–ç•¥

Select-MoE é‡‡ç”¨å…ˆè¿›çš„èšç±»-è½®é€‰ç­–ç•¥ï¼Œç¡®ä¿é€‰æ‹©æ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ï¼š

**ç¬¬ä¸€æ­¥ï¼šç‰¹å¾æå–**
- ä½¿ç”¨é¢„çƒ­çš„ Select-MoE Router å¤„ç†æ•°æ®ï¼Œè·å– MoE logits ä½œä¸ºè¯­ä¹‰ç‰¹å¾
- å°†æ¯ä¸ªæ ·æœ¬çš„ `[åºåˆ—é•¿åº¦, ä¸“å®¶æ•°]` ç‰¹å¾å±•å¹³ä¸ºä¸€ç»´å‘é‡
- æ„å»ºç‰¹å¾çŸ©é˜µ `[æ ·æœ¬æ•°, ç‰¹å¾ç»´åº¦]` ç”¨äºèšç±»

**ç¬¬äºŒæ­¥ï¼šGPUåŠ é€Ÿèšç±»**
```python
# K-Means + Elbow Method (è‡ªåŠ¨kå€¼é€‰æ‹©)
kmeans = GPUKMeansClustering(device='cuda')
labels = kmeans.find_optimal_k_elbow(features, k_range=[10, 100])

# HDBSCAN (æ— å‚æ•°å¯†åº¦èšç±»)
hdbscan = GPUHDBSCANClustering(device='cuda') 
labels = hdbscan.fit_predict(features, metric='cosine')
```

**ç¬¬ä¸‰æ­¥ï¼šè½®é€‰é«˜è´¨é‡æ•°æ®**
- å°†æ•°æ®æŒ‰èšç±»æ ‡ç­¾åˆ†ç»„åˆ°å„ä¸ªç°‡ä¸­
- åœ¨æ¯ä¸ªç°‡å†…æŒ‰è´¨é‡åˆ†æ•°é™åºæ’åˆ—
- è½®æµä»å„ç°‡é€‰æ‹©æœ€é«˜è´¨é‡æ ·æœ¬ï¼Œç›´åˆ°è¾¾åˆ°ç›®æ ‡æ•°é‡
- ç¡®ä¿æœ€ç»ˆæ•°æ®é›†åœ¨ä¿è¯é«˜è´¨é‡çš„åŒæ—¶å…·æœ‰è¯­ä¹‰å¤šæ ·æ€§

**ç®—æ³•ä¼˜åŠ¿**:
1. **è´¨é‡ä¿è¯**: åŸºäºRouterè´¨é‡è¯„åˆ†ï¼Œç¡®ä¿é€‰æ‹©é«˜è´¨é‡æ•°æ®
2. **å¤šæ ·æ€§ä¿è¯**: èšç±»ç¡®ä¿è¦†ç›–ä¸åŒè¯­ä¹‰åŒºåŸŸ
3. **GPUåŠ é€Ÿ**: æ”¯æŒå¤§è§„æ¨¡æ•°æ®å¤„ç†ï¼ˆ270k+æ ·æœ¬ï¼‰
4. **è‡ªé€‚åº”å‚æ•°**: K-Meansè‡ªåŠ¨kå€¼é€‰æ‹©ï¼ŒHDBSCANæ— éœ€é¢„è®¾å‚æ•°
5. **è¯­ä¹‰èšç±»**: ä½¿ç”¨ä½™å¼¦è·ç¦»å’ŒMoE logitsè¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦èšç±»

### ä¸¤å±‚è·¯ç”±æ¶æ„è®¾è®¡

Select-MoEé‡‡ç”¨åˆ›æ–°çš„ä¸¤å±‚è·¯ç”±æ¶æ„ï¼Œå®ç°æ›´ç²¾ç¡®çš„æ•°æ®è´¨é‡åˆ¤åˆ«ï¼š

**ç¬¬ä¸€å±‚ï¼šè´¨é‡é—¨ (Quality Gate)**
- è¿›è¡ŒäºŒå…ƒåˆ†ç±»ï¼šå¥½æ•°æ® vs åæ•°æ®
- è¾“å‡ºgood_ratioå’Œbad_ratioï¼Œæ§åˆ¶åç»­å¤„ç†æƒé‡
- ä½¿ç”¨å°å‹å…¨è¿æ¥ç½‘ç»œï¼Œè®¡ç®—æ•ˆç‡é«˜

**ç¬¬äºŒå±‚ï¼šå¹¶è¡Œå¤„ç†**
```
y = good_ratio * y_normal + bad_ratio * y_trash
```
- **æ­£å¸¸è·¯å¾„**: é€šè¿‡æ ‡å‡†MoEå¤„ç†ï¼Œä¿æŒåŸå§‹OLMoEèƒ½åŠ›
- **åƒåœ¾è·¯å¾„**: é€šè¿‡åƒåœ¾ä¸“å®¶å¤„ç†ï¼Œå¯é…ç½®è¾“å‡ºæ¨¡å¼
- **åŠ æƒç»„åˆ**: åŸºäºè´¨é‡é—¨è¾“å‡ºåŠ¨æ€ç»„åˆä¸¤è·¯ç»“æœ

### è´¨é‡åˆ†ç±»æŸå¤± - **æ›´æ–°æ¶æ„**

æ–°æ¶æ„é‡‡ç”¨æ›´ç®€æ´ç›´æ¥çš„è´¨é‡åˆ†ç±»æŸå¤±ï¼š

**å•åˆ†æ•°æ¶æ„** (å½“å‰ç‰ˆæœ¬):
```python
# è´¨é‡é—¨è¾“å‡ºå•ä¸ªåŸå§‹åˆ†æ•°
quality_score = quality_gate(hidden_states)  # å½¢çŠ¶: [batch, seq_len, 1]

# ç›´æ¥åº”ç”¨sigmoidå¾—åˆ°good_ratio
good_ratio = torch.sigmoid(quality_score)    # å½¢çŠ¶: [batch, seq_len, 1]
bad_ratio = 1.0 - good_ratio                 # å½¢çŠ¶: [batch, seq_len, 1]

# è´¨é‡æŸå¤±ï¼šç›´æ¥å¯¹good_ratioè®¡ç®—
L_quality = good_ratio.mean()  # é¼“åŠ±é™ä½good_ratio
```

**æŸå¤±ç‰¹æ€§**ï¼š
- **ç®€åŒ–è®¡ç®—**: å•åˆ†æ•° â†’ sigmoidï¼Œé¿å…softmaxçš„å¤æ‚æ€§
- **æ›´å¥½æ¢¯åº¦**: ç›´æ¥åœ¨åŸå§‹åˆ†æ•°ä¸Šåº”ç”¨sigmoidï¼Œæ¢¯åº¦æ›´æ¸…æ™°
- **å¡«å……å¤„ç†**: è‡ªåŠ¨æ’é™¤padding tokensï¼Œåªå¯¹æœ‰æ•ˆtokenè®¡ç®—æŸå¤±
- **å¯æ‰©å±•æ€§**: æ”¯æŒå¤šç§æŸå¤±ç±»å‹ (sigmoid, MSE, è‡ªå®šä¹‰å‡½æ•°)

**æŸå¤±ç±»å‹å¯¹æ¯”**ï¼š
```python
# sigmoidæŸå¤± (é»˜è®¤)
loss = good_ratio  # é¼“åŠ±é™ä½good_ratio

# MSEæŸå¤±
loss = (good_ratio - 0.0) ** 2  # æ˜ç¡®æ¨å‘0

# è‡ªå®šä¹‰æŸå¤±
loss = custom_loss_fn(good_ratio, attention_mask)  # ç”¨æˆ·å®šä¹‰
```

**æ€»æŸå¤±æ„æˆ**ï¼š
```
L_total = L_language_modeling + w_load_balancing * L_load_balancing + w_quality * L_quality
```

### åƒåœ¾ä¸“å®¶æœºåˆ¶

**è¾“å‡ºæ¨¡å¼**ï¼š
- **zeroæ¨¡å¼**: è¾“å‡ºé›¶å‘é‡ï¼Œæä¾›æœ€å°å¹²æ‰°
- **noiseæ¨¡å¼**: è¾“å‡ºä¸è¾“å…¥åŒåˆ†å¸ƒçš„å™ªå£°
- **customæ¨¡å¼**: æ”¯æŒè‡ªå®šä¹‰è¡Œä¸ºæ‰©å±•

**è®¾è®¡ä¼˜åŠ¿**ï¼š
1. **æ¨¡å—åŒ–**: åƒåœ¾ä¸“å®¶ç‹¬ç«‹äºMoEï¼Œæ˜“äºè°ƒè¯•å’Œä¼˜åŒ–
2. **å¯é…ç½®**: æ ¹æ®ä»»åŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„è¾“å‡ºæ¨¡å¼
3. **é«˜æ•ˆ**: é¿å…äº†å¤æ‚çš„ä¸“å®¶æ‰©å±•å’Œæƒé‡ç®¡ç†

## ğŸš§ å¼€å‘è®¡åˆ’

1. **åƒåœ¾æ¡¶ä¸“å®¶ä¼˜åŒ–**: å®ç°æ›´æ™ºèƒ½çš„åƒåœ¾æ¡¶ä¸“å®¶åˆå§‹åŒ–å’Œè¡Œä¸ºç­–ç•¥
2. **å¤šä»»åŠ¡é€‚é…**: æ‰©å±•æ”¯æŒæ›´å¤šä¸‹æ¸¸ä»»åŠ¡çš„æ•°æ®é€‰æ‹©
3. **æ•ˆç‡ä¼˜åŒ–**: ä¼˜åŒ–è®­ç»ƒå’Œæ¨ç†æ•ˆç‡ï¼Œæ”¯æŒæ›´å¤§è§„æ¨¡æ¨¡å‹
4. **è¯„ä¼°æ‰©å±•**: å¢åŠ æ›´å¤šè¯„ä¼°æŒ‡æ ‡å’ŒåŸºå‡†æµ‹è¯•
5. **èšç±»ç®—æ³•æ‰©å±•**: æ”¯æŒæ›´å¤šèšç±»ç®—æ³•(å¦‚Spectral Clustering, Gaussian Mixture Model)
6. **åˆ†å¸ƒå¼èšç±»**: æ”¯æŒå¤šGPUåˆ†å¸ƒå¼èšç±»å¤„ç†è¶…å¤§è§„æ¨¡æ•°æ®é›†

