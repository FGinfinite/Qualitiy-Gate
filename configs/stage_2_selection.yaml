# @package _global_

stage: selection

# Global seed for reproducibility
seed: 42

# 模型配置
selector_model:
  # 预转换的质量门控模型路径（使用 scripts/convert_qwen_to_quality_gate.py 转换）
  # 这个路径必须与 Stage 1 使用的模型路径一致
  path: "converted_models/quality_gate_Qwen3-1.7B-Base"
  tokenizer_name: "Qwen/Qwen3-1.7B-Base"

# Stage 2: Data Selection Configuration (统计收集阶段)

# Hydra settings to create a timestamped output directory
hydra:
  run:
    dir: outputs/stage_2_selection/${now:%Y-%m-%d}/${now:%H-%M-%S}-${extract_config:${model_checkpoint_path}}
  sweep:
    dir: outputs/stage_2_selection
    subdir: ${now:%Y-%m-%d}/${now:%H-%M-%S}-${extract_config:${model_checkpoint_path}}
  job:
    config:
      override_dirname:
        kv_sep: "="
        item_sep: ","
        exclude_keys:
          - hydra.run.dir
          - hydra.sweep.dir
          - hydra.sweep.subdir

# Path to the stage 1 checkpoint directory
# 该目录包含训练好的质量门控权重: full_rank_weights.pt
# Stage 2 会加载 selector_model.path 的基础模型，然后应用这里的权重
model_checkpoint_path: "outputs/stage_1_warmup/2025-01-01/00-00-00-batch=16_lr=0.001_loss=sigmoid_lossWeight=1_sampleWise=True_tag=none"

# The final output path for the router data
output_path: "${hydra:run.dir}/router_data.pt"

tag: "none"

# Dataset configuration
dataset:
  # 本地数据集根目录（所有 local 数据集的根路径）
  local_dataset_dir: "dataset/train/processed"
  
  # 数据集列表（应与 stage 1 配置保持一致）
  datasets:
    # GSM8K 数据集 (7,473 个训练样本)
    - dataset_from: "hf"                    # 数据源: "local" 或 "hf"
      name: "openai/gsm8k"                  # HuggingFace 数据集路径
      dataset_name: "gsm8k"                 # 数据集名称（用于标识）
      subset: "main"                        # 子集名称（可选）
      split: "train"                        # 数据集分割
      format_type: "gsm8k"                  # 数据格式类型
      use_shared_memory: false              # 是否使用共享内存（可选）

    - dataset_from: "local"
      dataset_name: "faker_dataset_24k"  
      format_type: "standard"
      use_shared_memory: false

  # Common parameters
  shuffle: false
  max_sequence_length: 1024
  # 1.0 means using the full dataset
  subset_ratio: 1.0
  processing_num_workers: 10
  overwrite_cache: false

  # Sequence length sorting configuration
  sort_by_length: true  # 是否按字符串长度降序排列数据（推荐开启以优化推理效率）

# Data processing settings
data_process:
  batch_size: 32
