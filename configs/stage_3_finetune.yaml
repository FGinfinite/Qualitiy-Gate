# @package _global_

stage: finetune
# Stage 3: Fine-tuning Configuration

# Hydra Configuration
hydra:
  run:
    dir: outputs/stage_3_finetune/${now:%Y-%m-%d}/${now:%H-%M-%S}-MODEL=<|${extract_model_config:${training.batch_size},${training.learning_rate},${tag}}|>-DATA=<|${extract_data_config_conditional:${dataset.data_path},${dataset.mode}}|>
  sweep:
    dir: outputs/stage_3_finetune
    subdir: ${now:%Y-%m-%d}/${now:%H-%M-%S}-MODEL=<|${extract_model_config:${training.batch_size},${training.learning_rate},${tag}}|>-DATA=<|${extract_data_config_conditional:${dataset.data_path},${dataset.mode}}|>
  job:
    config:
      override_dirname:
        kv_sep: "="
        item_sep: ","
        exclude_keys:
          - hydra.run.dir
          - hydra.sweep.dir
          - hydra.sweep.subdir

tag: "none"

# Global seed for reproducibility
seed: 42

defaults:
  - _self_
  - training: qwen_2.5_1.5b


output_dir: ${hydra:run.dir}

# Dataset configuration
dataset:
  # Data source selection for full mode: "local" or "hf"
  dataset_from: "hf"  # Options: "local" (本地数据集), "hf" (HuggingFace数据集)
  
  # Local dataset configuration (used when dataset_from="local" and mode="full")
  local:
    data_dir: "dataset/train/processed"
    dataset_names:
      - "cot"
      - "dolly"
      - "flan_v2"
      - "oasst1"
  
  # HuggingFace dataset configuration (used when dataset_from="hf" and mode="full")
  hf:
    datasets:
      - name: "teknium/OpenHermes-2.5"
        dataset_name: "openhermes"
        subset: null
        split: "train"
  
  # Common parameters
  subset_ratio: 1.0  # Use 100% of data in full mode
  # For subset mode: load from selected data file
  data_path: "outputs/stage_2_selection/2025-08-11/03-52-40-batch=8_lr=0.001_loss=beta_moment_matching_tag=none/selected_data.jsonl"
  max_sequence_length: 1024
  processing_num_workers: 10
  overwrite_cache: false
  mode: "subset" # "full" or "subset"
  shuffle: true # Enable data shuffling

gpu_grab:
  grab: false
  memory_need_gb: 24
  over_grab: false