# @package _global_

stage: finetune
# Stage 3: Fine-tuning Configuration

# Hydra Configuration
hydra:
  run:
    dir: outputs/stage_3_finetune/${now:%Y-%m-%d}/${now:%H-%M-%S}-batch=${training.batch_size},lr=${training.learning_rate},tag=${tag}
  sweep:
    dir: outputs/stage_3_finetune
    subdir: ${now:%Y-%m-%d}/${now:%H-%M-%S}-batch=${training.batch_size},lr=${training.learning_rate}-${hydra.job.override_dirname}
  job:
    config:
      override_dirname:
        kv_sep: "="
        item_sep: ","
        exclude_keys:
          - hydra.run.dir
          - hydra.sweep.dir
          - hydra.sweep.subdir

tag: "none"

defaults:
  - _self_
  - training: qwen_3_1.7b


# Model configuration
# model:
#   name: "meta-llama/Llama-2-7b-hf"

output_dir: ${hydra:run.dir}

# Dataset configuration - 使用选择后的数据
dataset:
  data_path: "outputs/stage_2_selection/2025-08-09/13-27-39-lr=1e-3/selected_data.jsonl"
  max_sequence_length: 1024
  processing_num_workers: 10
  overwrite_cache: false

gpu_grab:
  grab: false
  memory_need_gb: 24
  over_grab: false