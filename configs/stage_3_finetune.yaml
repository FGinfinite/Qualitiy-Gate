# @package _global_

# Stage 3: Fine-tuning Configuration

# Hydra settings
hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}/stage_3_finetune

# Stage identifier
stage: finetune

# Target Model configuration
target_model:
  name: "Qwen/Qwen2-1.5B" # As specified in the design doc

# Training configuration
training:
  data_path: "outputs/selected_data.jsonl" # Placeholder, assuming stage 2 output is here
  epochs: 1
  batch_size: 2 # Per-device batch size
  learning_rate: 2e-4
  max_length: 512
  peft_config:
    r: 16
    lora_alpha: 32
    lora_dropout: 0.05
    bias: "none"
    task_type: "CAUSAL_LM"

# Accelerate configuration injected for the Trainer
accelerate_config:
  use_fp16: false
  use_bf16: true # Enabled in accelerate_config.yaml
  use_deepspeed: true
  deepspeed_config_path: "configs/accelerate_config.yaml"

# Output configuration
output:
  adapter_save_path: "outputs/qwen2-1.5b-lora-adapter"