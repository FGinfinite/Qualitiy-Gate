# Single GPU Configuration for Finetune Stage (Llama-2-7B)
# Optimized for LoRA fine-tuning with Llama-2-7B model on single GPU

compute_environment: LOCAL_MACHINE
distributed_type: 'NO'  # No distributed training for single GPU
downcast_bf16: 'no'
gpu_ids: 'all'
machine_rank: 0
main_training_function: main
mixed_precision: 'bf16'
num_machines: 1
num_processes: 1
rdzv_backend: 'static'
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false