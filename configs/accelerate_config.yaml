# Accelerate Config for DeepSpeed ZeRO Stage 2
# This configuration is optimized for multi-GPU training.

compute_environment: "LOCAL_MACHINE"
deepspeed_config:
  deepspeed_multinode_launcher: "standard"
  gradient_accumulation_steps: 1
  offload_optimizer_device: "cpu"
  offload_param_device: "cpu"
  zero3_init_flag: false
  zero_stage: 2
distributed_type: "DEEPSPEED"
downcast_bf16: "no"
machine_rank: 0
main_training_function: "main"
mixed_precision: "bf16" # Use bf16 for better performance on modern GPUs
num_machines: 1
num_processes: 2 # Adjust based on the number of GPUs
rdzv_backend: "static"
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false