# @package _global_

# Stage 1: Pre-training Configuration

# Hydra settings
hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}/stage_1_pretrain

# Model configuration
model:
  name: "placeholder_model"
  tokenizer_name: "placeholder_tokenizer"
  learning_rate: 1e-5

# Dataset configuration
dataset:
  path: "placeholder/path/to/dataset"
  batch_size: 4
  max_length: 512

# Training configuration
training:
  epochs: 1
  optimizer: "AdamW"
  scheduler: "linear"