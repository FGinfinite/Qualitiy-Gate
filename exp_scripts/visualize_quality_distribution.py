#!/usr/bin/env python3
"""
è´¨é‡åˆ†æ•°åˆ†å¸ƒå¯è§†åŒ–è„šæœ¬

è¯¥è„šæœ¬åŠ è½½ router_data æ–‡ä»¶ï¼Œä½¿ç”¨ä¸åŒçš„è´¨é‡è®¡ç®—ç­–ç•¥ï¼Œ
å¹¶ç»˜åˆ¶è´¨é‡åˆ†æ•°çš„åˆ†å¸ƒç›´æ–¹å›¾ï¼Œç”¨äºéªŒè¯å›°æƒ‘åº¦åŠ æƒå’Œåˆ—å½’ä¸€åŒ–çš„æœ‰æ•ˆæ€§ã€‚

ä½¿ç”¨æ–¹æ³•:
    python exp_scripts/visualize_quality_distribution.py \
        --router-data-dir outputs/stage_2_selection/.../router_data \
        --output quality_distribution.png
"""

import argparse
from pathlib import Path
from typing import Dict, List, Tuple

import matplotlib.pyplot as plt
import numpy as np
import torch

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams["font.family"] = "sans-serif"
plt.rcParams["font.sans-serif"] = ["Noto Sans CJK SC"]
plt.rcParams["axes.unicode_minus"] = False


def load_router_data(router_data_path: str) -> dict:
    """åŠ è½½è·¯ç”±æ•°æ®"""
    data = torch.load(router_data_path, map_location="cpu")
    return data


def compute_token_weights(perplexities: torch.Tensor, alpha: float = 1.0, eps: float = 1e-8) -> torch.Tensor:
    """è®¡ç®—æ ·æœ¬å†…tokenæƒé‡ï¼ˆé«˜ç†µæ›´é‡è¦ï¼‰"""
    ppl_powered = torch.pow(perplexities, alpha)
    weights = ppl_powered / (ppl_powered.sum() + eps)
    return weights


def compute_layer_scores(
    quality_gates: torch.Tensor,
    perplexities: torch.Tensor,
    alpha: float = 1.0,
    eps: float = 1e-8,
) -> torch.Tensor:
    """æŒ‰tokenåŠ æƒå¾—åˆ°é€å±‚åˆ†æ•°"""
    weights = compute_token_weights(perplexities, alpha, eps)
    layer_scores = (quality_gates * weights[None, :]).sum(dim=1)
    return layer_scores


def one_step_mapping(S: np.ndarray, eps: float = 1e-8, tau: float = 0.0) -> np.ndarray:
    """é€å±‚å½’ä¸€åŒ–æ˜ å°„"""
    a = S.min(axis=0)
    b = S.max(axis=0)
    mu = S.mean(axis=0)

    if tau > 0:
        den = np.maximum(b - a, eps) * (mu + tau)
    else:
        den = np.maximum(b - a, eps) * np.maximum(mu, eps)

    R = (S - a[None, :]) / den[None, :]
    return R


def method_1_full(
    all_quality_gates: List[torch.Tensor], all_perplexities: List[torch.Tensor], alpha: float = 1.0, eps: float = 1e-8, tau: float = 0.0
) -> np.ndarray:
    """æ–¹æ³•1: å®Œæ•´æ–¹æ³•ï¼ˆå›°æƒ‘åº¦åŠ æƒ + åˆ—å½’ä¸€åŒ–ï¼‰"""
    # è®¡ç®—é€å±‚åˆ†æ•°
    S_rows = []
    for quality_gates, perplexities in zip(all_quality_gates, all_perplexities):
        layer_scores = compute_layer_scores(quality_gates, perplexities, alpha, eps)
        S_rows.append(layer_scores.cpu().numpy())

    S = np.stack(S_rows, axis=0)

    # åˆ—å½’ä¸€åŒ–
    R = one_step_mapping(S, eps, tau)

    # è®¡ç®—è´¨é‡åˆ†æ•°
    q = R.mean(axis=1)

    # Min-Maxå½’ä¸€åŒ–åˆ°[0, 1]
    q_normalized = (q - q.min()) / (q.max() - q.min() + eps)

    return q_normalized


def method_2_weighted_only(all_quality_gates: List[torch.Tensor], all_perplexities: List[torch.Tensor], alpha: float = 1.0, eps: float = 1e-8) -> np.ndarray:
    """æ–¹æ³•2: åªç”¨å›°æƒ‘åº¦åŠ æƒï¼Œä¸ç”¨åˆ—å½’ä¸€åŒ–"""
    # è®¡ç®—é€å±‚åˆ†æ•°
    S_rows = []
    for quality_gates, perplexities in zip(all_quality_gates, all_perplexities):
        layer_scores = compute_layer_scores(quality_gates, perplexities, alpha, eps)
        S_rows.append(layer_scores.cpu().numpy())

    S = np.stack(S_rows, axis=0)

    # ç›´æ¥æ±‚å‡å€¼ï¼ˆä¸åšåˆ—å½’ä¸€åŒ–ï¼‰
    q = S.mean(axis=1)

    # Min-Maxå½’ä¸€åŒ–åˆ°[0, 1]
    q_normalized = (q - q.min()) / (q.max() - q.min() + eps)

    return q_normalized


def method_3_normalized_only(all_quality_gates: List[torch.Tensor], all_perplexities: List[torch.Tensor], eps: float = 1e-8, tau: float = 0.0) -> np.ndarray:
    """æ–¹æ³•3: åªç”¨åˆ—å½’ä¸€åŒ–ï¼Œä¸ç”¨å›°æƒ‘åº¦åŠ æƒï¼ˆç›´æ¥å¹³å‡ï¼‰"""
    # ç›´æ¥å¯¹æ¯å±‚æ±‚å¹³å‡ï¼ˆä¸ç”¨å›°æƒ‘åº¦åŠ æƒï¼‰
    S_rows = []
    for quality_gates, perplexities in zip(all_quality_gates, all_perplexities):
        # æ‰¾åˆ°æœ‰æ•ˆtokenï¼ˆå›°æƒ‘åº¦ > 0ï¼‰
        valid_mask = perplexities > 0
        valid_length = valid_mask.sum().item()

        if valid_length > 0:
            # å¯¹æ¯å±‚çš„æœ‰æ•ˆtokenæ±‚å¹³å‡
            layer_scores = quality_gates[:, :valid_length].mean(dim=1)
        else:
            layer_scores = quality_gates[:, :1].mean(dim=1)

        S_rows.append(layer_scores.cpu().numpy())

    S = np.stack(S_rows, axis=0)

    # åˆ—å½’ä¸€åŒ–
    R = one_step_mapping(S, eps, tau)

    # è®¡ç®—è´¨é‡åˆ†æ•°
    q = R.mean(axis=1)

    # Min-Maxå½’ä¸€åŒ–åˆ°[0, 1]
    q_normalized = (q - q.min()) / (q.max() - q.min() + eps)

    return q_normalized


def method_4_raw_mean(all_quality_gates: List[torch.Tensor], all_perplexities: List[torch.Tensor], eps: float = 1e-8) -> np.ndarray:
    """æ–¹æ³•4: ä»€ä¹ˆéƒ½ä¸ç”¨ï¼Œç›´æ¥å¯¹quality_gatesæ±‚å‡å€¼"""
    scores = []
    for quality_gates, perplexities in zip(all_quality_gates, all_perplexities):
        # æ‰¾åˆ°æœ‰æ•ˆtoken
        valid_mask = perplexities > 0
        valid_length = valid_mask.sum().item()

        if valid_length > 0:
            # å¯¹æ‰€æœ‰å±‚å’Œæ‰€æœ‰æœ‰æ•ˆtokenæ±‚å‡å€¼
            score = quality_gates[:, :valid_length].mean().item()
        else:
            score = quality_gates[:, :1].mean().item()

        scores.append(score)

    q = np.array(scores)

    # Min-Maxå½’ä¸€åŒ–åˆ°[0, 1]
    q_normalized = (q - q.min()) / (q.max() - q.min() + eps)

    return q_normalized


def prepare_data_from_router_data(router_data_dir: str) -> Tuple[Dict[str, np.ndarray], Dict[str, List]]:
    """ä»router_dataç›®å½•åŠ è½½æ‰€æœ‰æ•°æ®é›†çš„æ•°æ®"""
    router_data_dir = Path(router_data_dir)

    all_quality_gates = []
    all_perplexities = []
    all_dataset_names = []

    # æŸ¥æ‰¾æ‰€æœ‰router_dataæ–‡ä»¶
    for file_path in sorted(router_data_dir.glob("*_router_data.pt")):
        dataset_name = file_path.stem.replace("_router_data", "")

        print(f"åŠ è½½æ•°æ®é›†: {dataset_name} ({file_path.name})")
        router_data = load_router_data(str(file_path))

        quality_gates = router_data["quality_gates"]  # [N, L, max_seq_len]
        perplexities = router_data["perplexities"]  # [N, max_seq_len]
        num_samples = router_data["num_samples"]

        print(f"  æ ·æœ¬æ•°: {num_samples}")
        print(f"  è´¨é‡é—¨æ§å½¢çŠ¶: {quality_gates.shape}")
        print(f"  å›°æƒ‘åº¦å½¢çŠ¶: {perplexities.shape}")

        # æå–æ¯ä¸ªæ ·æœ¬çš„æœ‰æ•ˆæ•°æ®
        for i in range(num_samples):
            qg = quality_gates[i]  # [L, max_seq_len]
            ppl = perplexities[i]  # [max_seq_len]

            # æ‰¾åˆ°æœ‰æ•ˆé•¿åº¦
            valid_mask = ppl > 0
            valid_length = valid_mask.sum().item()

            if valid_length > 0:
                qg_valid = qg[:, :valid_length]
                ppl_valid = ppl[:valid_length]
            else:
                qg_valid = qg[:, :1]
                ppl_valid = ppl[:1]

            all_quality_gates.append(qg_valid)
            all_perplexities.append(ppl_valid)
            all_dataset_names.append(dataset_name)

    print(f"\næ€»æ ·æœ¬æ•°: {len(all_quality_gates)}")

    # è®¡ç®—4ç§æ–¹æ³•çš„è´¨é‡åˆ†æ•°
    print("\nè®¡ç®—è´¨é‡åˆ†æ•°...")
    print("  æ–¹æ³•1: å®Œæ•´æ–¹æ³•ï¼ˆå›°æƒ‘åº¦åŠ æƒ + åˆ—å½’ä¸€åŒ–ï¼‰")
    scores_method1 = method_1_full(all_quality_gates, all_perplexities)

    print("  æ–¹æ³•2: åªç”¨å›°æƒ‘åº¦åŠ æƒ")
    scores_method2 = method_2_weighted_only(all_quality_gates, all_perplexities)

    print("  æ–¹æ³•3: åªç”¨åˆ—å½’ä¸€åŒ–")
    scores_method3 = method_3_normalized_only(all_quality_gates, all_perplexities)

    print("  æ–¹æ³•4: åŸå§‹å‡å€¼")
    scores_method4 = method_4_raw_mean(all_quality_gates, all_perplexities)

    scores_dict = {
        "method1": scores_method1,
        "method2": scores_method2,
        "method3": scores_method3,
        "method4": scores_method4,
    }

    data_dict = {
        "dataset_names": all_dataset_names,
    }

    return scores_dict, data_dict


def plot_distributions(scores_dict: Dict[str, np.ndarray], dataset_names: List[str], output_path: str, bin_width: float = 0.01):
    """ç»˜åˆ¶è´¨é‡åˆ†æ•°åˆ†å¸ƒå›¾

    Args:
        scores_dict: å„æ–¹æ³•çš„è´¨é‡åˆ†æ•°å­—å…¸
        dataset_names: æ•°æ®é›†åç§°åˆ—è¡¨
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„
        bin_width: ç›´æ–¹å›¾binå®½åº¦ï¼ˆé»˜è®¤0.01å³1%ï¼‰
    """
    # è®¾ç½®å›¾è¡¨æ ·å¼
    plt.style.use("seaborn-v0_8-whitegrid")
    fig, axes = plt.subplots(2, 2, figsize=(18, 14))
    axes = axes.flatten()

    # è·å–æ‰€æœ‰å”¯ä¸€çš„æ•°æ®é›†åç§°
    unique_datasets = sorted(list(set(dataset_names)))
    print(f"\næ•°æ®é›†åˆ—è¡¨: {unique_datasets}")

    # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ†é…é¢œè‰²ï¼ˆä½¿ç”¨æ›´é²œæ˜çš„é¢œè‰²ï¼‰
    color_palette = ["#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", "#8c564b", "#e377c2", "#7f7f7f"]
    dataset_colors = {dataset: color_palette[i % len(color_palette)] for i, dataset in enumerate(unique_datasets)}

    method_names = [
        "Method 1: Full Method (Perplexity Weighted + Column Normalization)",
        "Method 2: Perplexity Weighted Only (No Column Normalization)",
        "Method 3: Column Normalization Only (No Perplexity Weighting)",
        "Method 4: Raw Mean (No Special Processing)",
    ]

    method_keys = ["method1", "method2", "method3", "method4"]

    for idx, (ax, method_name, method_key) in enumerate(zip(axes, method_names, method_keys)):
        scores = scores_dict[method_key]

        # ğŸ”§ ä¸ºå½“å‰æ–¹æ³•è‡ªé€‚åº”è®¡ç®—binså’Œxè½´èŒƒå›´
        score_min = scores.min()
        score_max = scores.max()
        score_range = score_max - score_min

        # ç•™ä¸€äº›è¾¹è·ï¼ˆ5%ï¼‰
        padding = score_range * 0.05
        x_min = max(0, score_min - padding)
        x_max = min(1, score_max + padding)

        # åŠ¨æ€è®¡ç®—binsï¼šä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„binå®½åº¦
        num_bins = int(np.ceil((x_max - x_min) / bin_width))
        bins = np.linspace(x_min, x_max, num_bins + 1)

        print(f"\n{method_name}:")
        print(f"  æ•°æ®èŒƒå›´: [{score_min:.4f}, {score_max:.4f}]")
        print(f"  Xè½´èŒƒå›´: [{x_min:.4f}, {x_max:.4f}]")
        print(f"  Binå®½åº¦: {bin_width:.4f} ({bin_width * 100:.2f}%)")
        print(f"  Binsæ•°é‡: {num_bins}")

        # ä¸ºæ¯ä¸ªæ•°æ®é›†ç»˜åˆ¶æŸ±çŠ¶å›¾
        for dataset in unique_datasets:
            # ç­›é€‰å½“å‰æ•°æ®é›†çš„åˆ†æ•°
            mask = np.array([name == dataset for name in dataset_names])
            dataset_scores = scores[mask]

            # ç»˜åˆ¶ç›´æ–¹å›¾
            ax.hist(
                dataset_scores,
                bins=bins,
                alpha=0.65,
                color=dataset_colors[dataset],
                label=f"{dataset} (n={len(dataset_scores)})",
                edgecolor="black",
                linewidth=0.8,
            )

        # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
        ax.set_title(method_name, fontsize=13, fontweight="bold", pad=15)
        ax.set_xlabel("Quality Score", fontsize=11, fontweight="bold")
        ax.set_ylabel("Number of Samples", fontsize=11, fontweight="bold")

        # ğŸ”§ è®¾ç½®è‡ªé€‚åº”çš„xè½´èŒƒå›´
        ax.set_xlim(x_min, x_max)

        # ğŸ”§ è®¾ç½®è‡ªé€‚åº”çš„xè½´åˆ»åº¦ï¼ˆæ¯éš”1%æ˜¾ç¤ºä¸€ä¸ªæ ‡ç­¾ï¼Œé¿å…è¿‡äºå¯†é›†ï¼‰
        tick_step = 0.01  # æ¯éš”1%æ˜¾ç¤ºä¸€ä¸ªåˆ»åº¦
        tick_start = np.ceil(x_min / tick_step) * tick_step
        tick_end = np.floor(x_max / tick_step) * tick_step
        tick_positions = np.arange(tick_start, tick_end + tick_step / 2, tick_step)

        # å¦‚æœåˆ»åº¦å¤ªå°‘ï¼ˆ<5ä¸ªï¼‰ï¼Œå°±å¢åŠ å¯†åº¦
        if len(tick_positions) < 5:
            tick_step = 0.005  # æ”¹ä¸ºæ¯éš”0.5%
            tick_start = np.ceil(x_min / tick_step) * tick_step
            tick_end = np.floor(x_max / tick_step) * tick_step
            tick_positions = np.arange(tick_start, tick_end + tick_step / 2, tick_step)

        ax.set_xticks(tick_positions)
        ax.set_xticklabels([f"{x:.3f}" for x in tick_positions], rotation=45, ha="right", fontsize=9)

        # è®¾ç½®yè½´åˆ»åº¦
        ax.tick_params(axis="y", labelsize=9)

        # æ·»åŠ ç½‘æ ¼
        ax.grid(True, alpha=0.3, linestyle="--", linewidth=0.5)

        # æ·»åŠ å›¾ä¾‹
        ax.legend(loc="upper right", fontsize=10, framealpha=0.9)

        # æ·»åŠ å‚ç›´çº¿æ ‡è®°ä¸­ä½æ•°
        for dataset in unique_datasets:
            mask = np.array([name == dataset for name in dataset_names])
            dataset_scores = scores[mask]
            median = np.median(dataset_scores)
            ax.axvline(median, color=dataset_colors[dataset], linestyle="--", linewidth=1.5, alpha=0.8)

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"\n{method_name}:")
        for dataset in unique_datasets:
            mask = np.array([name == dataset for name in dataset_names])
            dataset_scores = scores[mask]
            print(
                f"  {dataset}: "
                f"å‡å€¼={dataset_scores.mean():.4f}, "
                f"æ ‡å‡†å·®={dataset_scores.std():.4f}, "
                f"ä¸­ä½æ•°={np.median(dataset_scores):.4f}, "
                f"[25%, 75%]=({np.percentile(dataset_scores, 25):.4f}, {np.percentile(dataset_scores, 75):.4f})"
            )

    # æ·»åŠ æ€»æ ‡é¢˜
    fig.suptitle("Quality Score Distribution Comparison: Effects of Different Calculation Methods", fontsize=16, fontweight="bold", y=0.995)

    plt.tight_layout(rect=[0, 0, 1, 0.99])
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    print(f"\nâœ… å›¾è¡¨å·²ä¿å­˜åˆ°: {output_path}")
    plt.close()


def print_separation_analysis(scores_dict: Dict[str, np.ndarray], dataset_names: List[str]):
    """æ‰“å°æ•°æ®é›†åˆ†ç¦»åº¦åˆ†æ"""
    print("\n" + "=" * 80)
    print("æ•°æ®é›†åˆ†ç¦»åº¦åˆ†æ")
    print("=" * 80)

    unique_datasets = sorted(list(set(dataset_names)))
    method_keys = ["method1", "method2", "method3", "method4"]
    method_names = ["æ–¹æ³•1ï¼ˆå®Œæ•´ï¼‰", "æ–¹æ³•2ï¼ˆåŠ æƒï¼‰", "æ–¹æ³•3ï¼ˆå½’ä¸€åŒ–ï¼‰", "æ–¹æ³•4ï¼ˆåŸå§‹ï¼‰"]

    for method_key, method_name in zip(method_keys, method_names):
        scores = scores_dict[method_key]

        print(f"\n{method_name}:")

        if len(unique_datasets) == 2:
            # å¦‚æœåªæœ‰ä¸¤ä¸ªæ•°æ®é›†ï¼Œè®¡ç®—å®ƒä»¬ä¹‹é—´çš„åˆ†ç¦»åº¦
            dataset1, dataset2 = unique_datasets
            mask1 = np.array([name == dataset1 for name in dataset_names])
            mask2 = np.array([name == dataset2 for name in dataset_names])

            scores1 = scores[mask1]
            scores2 = scores[mask2]

            mean1 = scores1.mean()
            mean2 = scores2.mean()
            std1 = scores1.std()
            std2 = scores2.std()

            # Cohen's d (æ•ˆåº”é‡)
            pooled_std = np.sqrt((std1**2 + std2**2) / 2)
            cohens_d = abs(mean1 - mean2) / pooled_std if pooled_std > 0 else 0

            print(f"  {dataset1} vs {dataset2}:")
            print(f"    å‡å€¼å·®å¼‚: {abs(mean1 - mean2):.4f}")
            print(f"    Cohen's d: {cohens_d:.4f} ", end="")

            if cohens_d < 0.2:
                print("(å¯å¿½ç•¥)")
            elif cohens_d < 0.5:
                print("(å°)")
            elif cohens_d < 0.8:
                print("(ä¸­)")
            else:
                print("(å¤§)")

            # é‡å åº¦ï¼ˆé€šè¿‡åˆ†ä½æ•°ä¼°è®¡ï¼‰
            q25_1 = np.percentile(scores1, 25)
            q75_1 = np.percentile(scores1, 75)
            q25_2 = np.percentile(scores2, 25)
            q75_2 = np.percentile(scores2, 75)

            if mean1 > mean2:
                overlap = max(0, min(q75_2, q75_1) - max(q25_1, q25_2))
            else:
                overlap = max(0, min(q75_1, q75_2) - max(q25_2, q25_1))

            print(f"    åˆ†ä½æ•°é‡å åŒºé—´: {overlap:.4f}")


def main():
    parser = argparse.ArgumentParser(description="å¯è§†åŒ–è´¨é‡åˆ†æ•°åˆ†å¸ƒ")
    parser.add_argument("--router-data-dir", required=True, help="router_dataç›®å½•è·¯å¾„")
    parser.add_argument("--output", default="quality_distribution.png", help="è¾“å‡ºå›¾ç‰‡è·¯å¾„ (é»˜è®¤: quality_distribution.png)")
    parser.add_argument("--bin-width", type=float, default=0.01, help="ç›´æ–¹å›¾binå®½åº¦ (é»˜è®¤: 0.01å³1%%)")
    parser.add_argument("--analyze", action="store_true", help="æ‰“å°è¯¦ç»†çš„åˆ†ç¦»åº¦åˆ†æ")

    args = parser.parse_args()

    print("=" * 80)
    print("è´¨é‡åˆ†æ•°åˆ†å¸ƒå¯è§†åŒ–")
    print("=" * 80)
    print(f"Router Data ç›®å½•: {args.router_data_dir}")
    print(f"è¾“å‡ºè·¯å¾„: {args.output}")
    print(f"Bin å®½åº¦: {args.bin_width} ({args.bin_width * 100:.2f}%)")

    # åŠ è½½æ•°æ®å¹¶è®¡ç®—è´¨é‡åˆ†æ•°
    scores_dict, data_dict = prepare_data_from_router_data(args.router_data_dir)

    # ç»˜åˆ¶åˆ†å¸ƒå›¾
    plot_distributions(scores_dict, data_dict["dataset_names"], args.output, bin_width=args.bin_width)

    # æ‰“å°åˆ†ç¦»åº¦åˆ†æ
    if args.analyze:
        print_separation_analysis(scores_dict, data_dict["dataset_names"])

    print("\n" + "=" * 80)
    print("å®Œæˆ!")
    print("=" * 80)


if __name__ == "__main__":
    main()
