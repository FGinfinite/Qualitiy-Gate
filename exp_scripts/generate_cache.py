#!/usr/bin/env python3
"""
ç”Ÿæˆfaissç¼“å­˜æ–‡ä»¶è„šæœ¬

ç”¨é€”ï¼šåœ¨æŒ‡å®šç›®å½•ç”Ÿæˆfaissç¼“å­˜æ–‡ä»¶
ä½¿ç”¨åœºæ™¯ï¼š
  - æµ‹è¯•faissç¼“å­˜æ–‡ä»¶ç”Ÿæˆ
  - æµ‹è¯•faissç¼“å­˜æ–‡ä»¶ä½¿ç”¨
  - æ¨¡æ‹Ÿfaissç¼“å­˜æ–‡ä»¶ä½¿ç”¨æƒ…å†µ
"""

import argparse
import os
from pathlib import Path


def parse_size(size_str: str) -> int:
    """
    è§£ææ–‡ä»¶å¤§å°å­—ç¬¦ä¸²

    Args:
        size_str: å¤§å°å­—ç¬¦ä¸²ï¼Œå¦‚ "10MB", "1GB", "500KB"

    Returns:
        å­—èŠ‚æ•°

    Examples:
        >>> parse_size("10MB")
        10485760
        >>> parse_size("1GB")
        1073741824
    """
    size_str = size_str.upper().strip()
    # æŒ‰å•ä½é•¿åº¦ä»é•¿åˆ°çŸ­æ’åºï¼Œé¿å… "GB" è¢« "B" å…ˆåŒ¹é…
    units = [
        ("TB", 1024**4),
        ("GB", 1024**3),
        ("MB", 1024**2),
        ("KB", 1024),
        ("B", 1),
    ]

    # æå–æ•°å­—å’Œå•ä½
    for unit, multiplier in units:
        if size_str.endswith(unit):
            try:
                number = float(size_str[: -len(unit)])
                return int(number * multiplier)
            except ValueError:
                raise ValueError(f"æ— æ•ˆçš„å¤§å°æ ¼å¼: {size_str}")

    # å¦‚æœæ²¡æœ‰å•ä½ï¼Œå‡è®¾æ˜¯å­—èŠ‚
    try:
        return int(size_str)
    except ValueError:
        raise ValueError(f"æ— æ•ˆçš„å¤§å°æ ¼å¼: {size_str}")


def format_size(size_bytes: int) -> str:
    """
    æ ¼å¼åŒ–å­—èŠ‚æ•°ä¸ºå¯è¯»å­—ç¬¦ä¸²

    Args:
        size_bytes: å­—èŠ‚æ•°

    Returns:
        å¯è¯»çš„å¤§å°å­—ç¬¦ä¸²
    """
    for unit in ["B", "KB", "MB", "GB", "TB"]:
        if size_bytes < 1024.0:
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.2f} PB"


def generate_trash_files(
    output_dir: str,
    total_size: str,
    num_files: int,
):
    """
    ç”Ÿæˆåƒåœ¾æ–‡ä»¶

    Args:
        output_dir: è¾“å‡ºç›®å½•
        total_size: æ€»å¤§å°ï¼ˆå¦‚ "1GB"ï¼‰
        num_files: æ–‡ä»¶æ•°é‡
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # æŸ¥æ‰¾å·²æœ‰æ–‡ä»¶çš„æœ€å¤§åºå·
    existing_files = list(output_path.glob("faiss_cache_*.pt"))
    start_index = 0

    if existing_files:
        # æå–æ‰€æœ‰åºå·
        indices = []
        for f in existing_files:
            try:
                # æ–‡ä»¶åæ ¼å¼: faiss_cache_N.pt
                index = int(f.stem.split("_")[-1])
                indices.append(index)
            except (ValueError, IndexError):
                continue

        if indices:
            start_index = max(indices) + 1
            print(f"ğŸ” å‘ç° {len(existing_files)} ä¸ªå·²æœ‰æ–‡ä»¶ï¼Œæœ€å¤§åºå·: {max(indices)}")
            print(f"ğŸ“Œ ä»åºå· {start_index} å¼€å§‹ç”Ÿæˆæ–°æ–‡ä»¶")
    else:
        print("ğŸ“Œ æœªå‘ç°å·²æœ‰æ–‡ä»¶ï¼Œä»åºå· 0 å¼€å§‹ç”Ÿæˆ")

    # è§£æå¤§å°
    total_bytes = parse_size(total_size)
    avg_file_size = total_bytes // num_files

    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_path.absolute()}")
    print(f"ğŸ“Š ç›®æ ‡æ€»å¤§å°: {format_size(total_bytes)}")
    print(f"ğŸ“„ æ–‡ä»¶æ•°é‡: {num_files}")
    print(f"ğŸ“ æ¯ä¸ªæ–‡ä»¶å¤§å°: {format_size(avg_file_size)}")
    print("-" * 60)

    total_written = 0
    files_created = 0

    try:
        for i in range(num_files):
            # è®¡ç®—å½“å‰æ–‡ä»¶å¤§å°ï¼ˆå›ºå®šå¹³å‡å€¼ï¼Œæœ€åä¸€ä¸ªæ–‡ä»¶å†™å…¥å‰©ä½™ç©ºé—´ï¼‰
            if i == num_files - 1:
                file_size = total_bytes - total_written
            else:
                file_size = avg_file_size

            # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨ start_index åç§»ï¼‰
            file_index = start_index + i
            filename = f"faiss_cache_{file_index}.pt"
            filepath = output_path / filename

            # ç”Ÿæˆå¹¶å†™å…¥æ•°æ®
            print(f"âš™ï¸  ç”Ÿæˆ {filename} ({format_size(file_size)})...", end=" ", flush=True)

            # å¯¹äºå¤§æ–‡ä»¶ï¼Œåˆ†å—å†™å…¥ä»¥é¿å…å†…å­˜é—®é¢˜
            chunk_size = 100 * 1024 * 1024  # 100MB chunks
            with open(filepath, "wb") as f:
                written = 0
                while written < file_size:
                    chunk = min(chunk_size, file_size - written)
                    data = os.urandom(chunk)
                    f.write(data)
                    written += chunk

            total_written += file_size
            files_created += 1
            print("âœ…")

            # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°ç›®æ ‡
            if total_written >= total_bytes:
                break

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ é”™è¯¯: {e}")

    print("-" * 60)
    print(f"âœ… å®Œæˆ! åˆ›å»º {files_created} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“Š æ€»å¤§å°: {format_size(total_written)} / {format_size(total_bytes)}")
    print(f"ğŸ“ ä½ç½®: {output_path.absolute()}")


def main():
    parser = argparse.ArgumentParser(
        description="ç”Ÿæˆåƒåœ¾æ–‡ä»¶ä»¥å ç”¨ç£ç›˜ç©ºé—´ (å›ºå®šæ–‡ä»¶å: faiss_cache_0.pt ~ faiss_cache_N.pt)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # ç”Ÿæˆæ€»å…± 1GB çš„åƒåœ¾æ–‡ä»¶ï¼Œåˆ†ä¸º 100 ä¸ªæ–‡ä»¶ (é»˜è®¤è¾“å‡ºåˆ° index_cache/)
  python generate_trash.py -s 1GB -n 100

  # ç”Ÿæˆ 100GBï¼Œåˆ†ä¸º 100 ä¸ªæ–‡ä»¶
  python generate_trash.py -s 100GB -n 100

  # ç”Ÿæˆ 500MBï¼Œåˆ†ä¸º 10 ä¸ªæ–‡ä»¶ï¼Œä¿å­˜åˆ°è‡ªå®šä¹‰ç›®å½•
  python generate_trash.py -s 500MB -n 10 -o /data/cache
        """,
    )

    parser.add_argument(
        "-s",
        "--size",
        type=str,
        required=True,
        help="æ€»å¤§å° (å¦‚: 1GB, 500MB, 100GB)",
    )

    parser.add_argument(
        "-n",
        "--num-files",
        type=int,
        required=True,
        help="ç”Ÿæˆçš„æ–‡ä»¶æ•°é‡",
    )

    parser.add_argument(
        "-o",
        "--output",
        type=str,
        default="outputs/index_cache",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: outputs/index_cache)",
    )

    args = parser.parse_args()

    # ç”Ÿæˆåƒåœ¾æ–‡ä»¶
    generate_trash_files(
        output_dir=args.output,
        total_size=args.size,
        num_files=args.num_files,
    )


if __name__ == "__main__":
    main()
