技术要点:
 - 评估：lm-eval
 - 训练后端：deepspeed
 - 启动指令：accelerate
 - 配置管理：hydra


功能描述：一个使用MOE模型进行“数据选择”的创新实验项目。

流程：
1. 模型预热：“选择模型”进行预热，在一个混合数据集上进行训练。比如在OpenHermes2.5上，使用1%的数据，训练4个epochs，并保存每个epochs的权重。
 - 要点：使用小型的MOE模型，比如HF上的Qwen/Qwen3-0.6B，仅对其中的Router权重进行训练。训练方式是全秩微调，不使用LoRA等技术。每个Epoch的训练结束，都保留其训练权重。
2. 数据选择：我们假设这个MOE模型在经过预热后，Router权重具有分辨数据质量的能力。比如如果有64个专家的那么router输出的0~55号专家代表了挑选好数据，56~63号的8个专家则代表了挑选坏的数据，可以看作是“垃圾桶”专家。对于需要挑选的数据集，我们应该使用这个训练后的MOE模型对每条数据都推理一次，并记录其中所有经过微调的Router权重的输出值。为每条数据计算出它们在所有Router前向传播后的0~55号专家的分数，并且计算其总得分（比如直接加起来），以此来排序。按照得分高低来挑选数据。
 - 要点：你应该将这个设置为可以配置的过程。例如，用超参数确定百分之多少的专家是“垃圾桶”。又要在什么数据集上总共挑选百分之多少的数据？
 - 注意：挑选后的数据你应该想好使用什么格式存储或记录，来自什么数据集，是多少号数据。以便在下一流程中使用这些数据来训练。
3. 模型训练：使用“目标模型”在挑选好的数据上训练，使用LoRA微调。训练流程与一般的流程没有太大区别，只是注意数据来源是上一步中挑选后的数据。
 - 要点：使用的模型可以是任意的大模型，比如Qwen/Qwen3-1.7B。注意记录loss变化。使用transformers和peft库来训练，deepspeed作为训练后端，使用accelerate来启动训练脚本。
4. 模型评估：使用lm-eval库来评估训练后的模型表现，目前评估的任务就是经典的MMLU即可。
 - 要点：记录下最常见的评估指标，得分等等。我不是这方面的专家，可能不同任务有各自的得分方式。请尽量使用lm-eval库所提供的统一API来完成这一评估过程。

整体要点：
 1. 以上四个流程，不同流程都会有各自的实验配置，请注意使用hydra进行有序的管理。
 2. 以上的各个环节我可能都会需要人为的修改，在各地方可能都需要快速地迭代或配置，核心代码也有可能会发生变动，以迅速地验证我的设想与猜想。所以在编写时，要注意注明各函数的输入与输出格式，使用正确的type hint，以便我后续的调试与开发。
