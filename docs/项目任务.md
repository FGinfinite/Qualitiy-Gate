## **项目任务进度：基于MoE路由器的数据选择与模型优化 (修订版)**

本文档将整个项目分解为5个核心开发任务。此版本已根据您的技术栈（`uv`包管理）和代码组织偏好（执行脚本与`src`分离）进行了调整。

### **任务 1：项目框架原则与环境搭建**

这是项目的基石，旨在建立一个符合工程实践、稳固且可配置的开发骨架。

* **🎯 核心目标**:
    确立项目代码的组织原则，并使用 `uv` 搭建一个隔离且完整的开发环境。

* **📋 具体要求**:
    1.  **确立目录结构特点**:
        -   **关注点分离**: 项目结构应清晰地将不同角色的文件分开。建议将**核心业务逻辑**统一管理在 `src` 目录中，将**配置文件**放在 `configs` 目录中，而所有实验产出（如模型、数据集、日志）都应重定向到统一的 `outputs` 目录。
        -   **执行与实现分离**: **执行入口**应为顶层的 `.sh` 脚本（例如 `run_stage_1.sh`），这些脚本负责设置环境、调用Python命令。实际的、复杂的Python逻辑则封装在 `src` 目录内，使得Shell脚本保持简洁，只负责“启动”。
    2.  **环境与依赖管理**:
        -   使用 `uv` 作为包管理工具。在`scripts`内的 `pyproject.toml` 文件中声明所有项目依赖（如 `hydra-core`, `torch`, `transformers`, `peft`, `accelerate`, `deepspeed`, `lm-eval-harness`）。
        -   使用 `uv venv` 创建虚拟环境，并使用 `uv pip install -e .` 或 `uv pip install -r requirements.txt` 安装所有依赖，确保 `src` 目录下的代码能作为可编辑包被识别。
    3.  **初始化 `Hydra` 配置**:
        -   在 `configs` 目录中，为四个阶段创建基础的 `.yaml` 配置文件。
        -   在配置文件中定义文档中提到的所有可配置项，并使用占位符或默认值。

* **✅ 完成标准**:
    -   项目遵循了配置、源码、产出分离的组织原则。
    -   可以使用 `uv` 命令成功创建环境并安装所有依赖。
    -   可以编写一个简单的 `run_test.sh` 脚本，该脚本能成功调用 `src` 内的一个Python函数，并让该函数加载 `Hydra` 配置。

### **任务 2：实现阶段一 - 选择模型预热**

* **🎯 核心目标**:
    在 `src` 目录中开发核心预热逻辑，并通过 `.sh` 脚本来执行。

* **📋 具体要求**:
    1.  **核心逻辑 (在 `src` 内)**:
        -   编写一个或多个Python模块（例如 `src/stages/pretrain.py`），用于实现选择模型的预热。
        -   该模块应包含：加载MoE模型、冻结非Router权重、实现全秩微调训练循环、以及按Epoch保存完整模型的功能。
        -   所有函数和方法都应使用明确的**类型提示**。
    2.  **执行脚本 (在`scripts`内)**:
        -   创建一个 `run_stage_1.sh` 脚本。
        -   此脚本负责调用Python解释器来运行 `src` 中预热逻辑的入口点，并通过命令行参数传入 `Hydra` 的配置信息。例如:
          ```bash
          #!/bin/bash
          uv run -m src.main_runner --config-name=stage_1_pretrain training.epochs=4
          ```

* **✅ 完成标准**:
    -   执行 `run_stage_1.sh` 脚本能成功启动并完成训练流程。
    -   在 `outputs` 目录下，能看到按Epoch保存的模型权重文件夹。

### **任务 3：实现阶段二 - 数据选择**

* **🎯 核心目标**:
    在 `src` 目录中开发数据打分与筛选的核心功能，并通过独立的 `.sh` 脚本调用。

* **📋 具体要求**:
    1.  **核心逻辑 (在 `src` 内)**:
        -   在 `src/stages/` 下创建 `selection.py` 模块。
        -   实现数据选择的全部逻辑：加载阶段一模型、根据比例定义优质/垃圾桶专家、实现 `calculate_quality_score` 函数、遍历数据集进行打分、排序、筛选，并最终按规定格式保存。
    2.  **执行脚本 (在`scripts`内)**:
        -   创建 `run_stage_2.sh` 脚本。
        -   该脚本调用 `src` 中的数据选择逻辑，并传入必要的配置，如阶段一的模型路径和目标数据集路径。

* **✅ 完成标准**:
    -   执行 `run_stage_2.sh` 脚本能成功完成数据筛选任务。
    -   在 `outputs` 目录下生成一个格式正确、包含所有要求字段的筛选后数据文件（`.jsonl` 或 `.parquet`）。

### **任务 4：实现阶段三 - 目标模型训练**

* **🎯 核心目标**:
    在 `src` 中实现由 `accelerate` 和 `deepspeed` 驱动的LoRA微调，并通过 `.sh` 脚本启动。

* **📋 具体要求**:
    1.  **核心逻辑 (在 `src` 内)**:
        -   在 `src/stages/` 下创建 `train_target.py` 模块。
        -   实现目标模型训练的逻辑：加载阶段二数据、加载目标模型、根据配置应用PEFT（LoRA）、实现与 `accelerate` 兼容的训练循环，并保存LoRA适配器。
    2.  **执行脚本 (在`scripts`内)**:
        -   创建 `run_stage_3.sh` 脚本。
        -   此脚本的核心是 `accelerate launch` 命令，它指向 `src` 中训练逻辑的入口点，并传递 `Hydra` 配置。例如：
          ```bash
          #!/bin/bash
          accelerate launch --config_file accelerate_config.yaml src/main_runner.py --config-name=stage_3_train
          ```

* **✅ 完成标准**:
    -   执行 `run_stage_3.sh` 脚本能成功启动一个（可能是分布式的）训练任务。
    -   训练结束后，在 `outputs` 目录下成功保存了LoRA适配器权重。

### **任务 5：实现阶段四 - 模型评估**

* **🎯 核心目标**:
    在 `src` 中封装 `lm-eval` 的调用流程，并通过 `.sh` 脚本执行最终的模型性能评估。

* **📋 具体要求**:
    1.  **核心逻辑 (在 `src` 内)**:
        -   在 `src/stages/` 下创建 `evaluate.py` 模块。
        -   实现模型评估的逻辑：加载基础模型、加载并合并阶段三的LoRA适配器、调用 `lm-eval-harness` 的API执行评估、解析并格式化评估结果。
    2.  **执行脚本 (在`scripts`内)**:
        -   创建 `run_stage_4.sh` 脚本。
        -   该脚本调用 `src` 中的评估逻辑，并传入模型及适配器的路径等配置。

* **✅ 完成标准**:
    -   执行 `run_stage_4.sh` 脚本能成功完成对已微调模型的评估。
    -   在 `outputs` 目录下生成一个包含MMLU等基准测试结果的JSON文件。