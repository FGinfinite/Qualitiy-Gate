## **项目设计文档：基于MoE路由器的数据选择与模型优化实验**

### **1. 项目概述 (Executive Summary)** 📝

本项目旨在探索一种创新的**数据选择 (Data Selection)** 方法。核心假设是：一个经过轻微预热的**混合专家模型 (Mixture-of-Experts, MoE)**，其内部的**路由器 (Router)** 权重能够学习到分辨数据质量的内在能力。

我们将通过一个四阶段的实验流程来验证这一假设：
1.  **预热选择模型**：对一个小型MoE模型的路由器进行微调。
2.  **执行数据选择**：利用预热后的模型，为数据集中的每条数据进行“质量”打分和排序。
3.  **训练目标模型**：使用筛选出的高质量数据，对一个更大的目标语言模型进行微调。
4.  **评估模型性能**：通过标准学术基准（如MMLU）来评估目标模型的性能提升。

本项目的最终目标是验证该数据选择方法的有效性，并形成一套可复用、可配置的实验流程，为未来大模型的高效训练提供新的思路。

---

### **2. 技术栈 (Tech Stack)** 💻

-   **模型评估 (Evaluation)**: `lm-eval`
-   **分布式训练后端 (Training Backend)**: `deepspeed`
-   **训练启动器 (Launcher)**: `accelerate`
-   **配置管理 (Configuration)**: `hydra`
-   **核心库 (Core Libraries)**: `transformers`, `peft`

---

### **3. 项目架构与工作流 (Architecture & Workflow)** 🚀

整个项目被划分为四个独立的、可配置的阶段。每个阶段都有明确的输入和输出，以便于独立调试和快速迭代。

#### **阶段一：选择模型预热 (Selector Model Pre-training)**

* **🎯 目标**:
    使一个小型MoE模型的Router权重学习到对不同数据特征的区分能力。我们称此模型为“选择模型 (Selector Model)”。

* **⚙️ 流程**:
    1.  **选择模型**: 使用一个轻量级的MoE模型，例如 `Qwen/Qwen3-0.6B`。
    2.  **训练目标**: **仅训练Router部分的权重**。模型主干（如Attention、FFN）的权重保持冻结。
    3.  **训练方式**: 采用**全秩微调 (Full-rank Fine-tuning)**，不使用LoRA等参数高效微调技术，以保证Router有足够的能力学习。
    4.  **数据集**: 在一个混合、通用的数据集（如 OpenHermes2.5 的1%子集）上进行训练。
    5.  **权重保存**: 每个Epoch训练结束后，**保存完整的模型权重**。这允许我们后续比较不同预热程度的Router对数据选择能力的影响。

* **➡️ 输出**:
    一系列模型权重文件，每个文件对应一个Epoch的训练结果。
    -   `{output_dir}/epoch_1/`
    -   `{output_dir}/epoch_2/`
    -   ...

* **🔧 `hydra` 可配置项**:
    -   `selector_model.name`
    -   `dataset.path`
    -   `training.epochs`
    -   `training.learning_rate`
    -   `output.model_save_path`

---

#### **阶段二：数据选择 (Data Selection)**

* **🎯 目标**:
    使用预热后的“选择模型”对目标数据集进行质量打分，并筛选出高质量子集。

* **⚙️ 流程**:
    1.  **加载模型**: 加载在阶段一中训练好的“选择模型”权重（例如，最后一个Epoch的权重）。
    2.  **定义专家角色**: 根据超参数，将一部分专家定义为“垃圾桶专家 (Trash Experts)”，其余为“优质专家 (Good Experts)”。
        -   例如，总共64个专家，可配置 `trash_expert_ratio: 0.125`，则后8个（64 * 0.125 = 8）为“垃圾桶”。
    3.  **数据推理与打分**:
        -   遍历待筛选数据集中的每一条数据。
        -   执行一次前向传播 (Forward Pass)。
        -   记录所有Router输出层在Softmax之前的原始Logits值。
        -   **计算质量分**: 将该条数据在所有“优质专家”上获得的Logits值相加，作为其最终的“质量得分”。
    4.  **数据排序与筛选**:
        -   根据“质量得分”对整个数据集进行降序排序。
        -   根据配置的筛选比例（例如 `selection_percentage: 0.05`），选取得分最高的5%数据。

* **➡️ 输出**:
    一个结构化的数据文件（推荐使用 `.jsonl` 或 `.parquet` 格式），用于阶段三的训练。文件中的每条记录应包含：
    ```json
    {
      "source_dataset": "original_dataset_name",
      "source_index": 12345,
      "text": "The actual data content...",
      "quality_score": 98.76
    }
    ```

* **🔧 `hydra` 可配置项**:
    -   `selector_model.checkpoint_path` (阶段一的输出路径)
    -   `data_selection.target_dataset_path`
    -   `data_selection.trash_expert_ratio`
    -   `data_selection.selection_percentage`
    -   `output.selected_data_path`

---

#### **阶段三：目标模型训练 (Target Model Training)**

* **🎯 目标**:
    在筛选出的高质量数据上，对一个“目标模型 (Target Model)”进行高效微调。

* **⚙️ 流程**:
    1.  **目标模型**: 可以是任意规模的语言模型，例如 `Qwen/Qwen3-1.7B`。
    2.  **数据来源**: 使用阶段二生成的筛选后数据集。
    3.  **训练方式**: 采用**LoRA**进行参数高效微调。
    4.  **训练执行**: 使用 `accelerate` 工具启动训练脚本，并利用 `deepspeed` (例如 ZeRO Stage 2/3) 作为后端来优化大规模模型训练的显存和效率。
    5.  **监控**: 记录并可视化训练过程中的**Loss变化曲线**，以便分析收敛情况。

* **➡️ 输出**:
    -   训练好的LoRA权重文件。
    -   Loss日志文件或TensorBoard日志。

* **🔧 `hydra` 可配置项**:
    -   `target_model.name`
    -   `training.data_path` (阶段二的输出)
    -   `training.peft_config` (包含`lora_r`, `lora_alpha`等)
    -   `training.learning_rate`, `training.num_epochs`
    -   `accelerate_config.yaml` (由accelerate管理)
    -   `output.adapter_save_path`

---

#### **阶段四：模型评估 (Model Evaluation)**

* **🎯 目标**:
    客观、可复现地评估“目标模型”在标准任务上的性能。

* **⚙️ 流程**:
    1.  **加载模型**: 加载基础的“目标模型”和在阶段三中训练好的LoRA权重，并将它们合并。
    2.  **评估框架**: 使用 `lm-eval` 库提供的标准API。
    3.  **评估任务**: 以 **MMLU** 作为核心评估基准。
    4.  **执行评估**: 运行 `lm-eval` 评估流程，并捕获其输出。

* **➡️ 输出**:
    一个包含评估结果的JSON或文本文件，记录 `lm-eval` 提供的各项标准指标（如MMLU的平均分和各子任务得分）。

* **🔧 `hydra` 可配置项**:
    -   `eval.model.base_model_path`
    -   `eval.model.adapter_path` (阶段三的输出)
    -   `eval.tasks` (例如: `['mmlu']`)
    -   `eval.batch_size`
    -   `output.results_path`

---

### **4. 核心设计要点与开发建议 (Key Design Principles & Recommendations)** 💡

为了确保项目的高效迭代和可维护性，您特别强调了以下几点，这正是优秀实验项目的关键：

1.  **高度模块化与配置驱动**:
    -   **Hydra为中心**: 所有的实验参数——从模型名称、学习率到文件路径——都应通过`hydra`进行管理。这使得可以通过命令行轻松覆盖配置，实现“不改代码，只改配置”的快速实验。
    -   **独立脚本**: 将四个阶段分别实现为独立的Python脚本 (`stage_1_pretrain.py`, `stage_2_select.py`, ...)。它们通过文件系统（读取上一阶段的输出）解耦，可以独立运行和测试。

2.  **代码清晰与可维护性**:
    -   **强制类型提示 (Type Hinting)**: 这是您提出的一个非常好的实践！所有函数和方法的签名都应使用明确的类型提示。
        ```python
        # 示例
        def calculate_quality_score(
            router_logits: torch.Tensor,
            good_expert_indices: list[int]
        ) -> float:
            """基于Router Logits来计算质量分数"""
            # ... function body ...
            return score
        ```
        这样做的好处是：
        -   **提升代码可读性**：任何人都能立刻明白函数的输入输出。
        -   **利于静态分析与IDE**：VS Code、PyCharm等工具能提供更智能的自动补全和错误检查。
        -   **降低调试难度**：从源头上避免了许多因数据类型不匹配导致的运行时错误。

3.  **明确的接口定义 (Clear I/O)**:
    -   在每个脚本的开头或文档字符串 (docstring) 中，明确注明其**输入依赖**（需要哪些文件或数据）和**输出产物**（会生成哪些文件）。
    -   **数据格式标准化**: 像阶段二输出的筛选后数据，定义统一的JSON结构，是保证流程顺畅的关键。
